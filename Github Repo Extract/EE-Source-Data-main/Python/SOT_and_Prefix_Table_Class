""" The purpose of this script is to offload the processing of the data behind the Source of Truth table (also known as
the Source of True Knowledge, SOT_KNOWLEDGE, or SOT_K). With the integration of {self.__discover} Policy Prefixes the
processing power of SQL is not enough to create the table."""

###############################
# Import Statement
import pandas as pd
import pyodbc
from itertools import combinations
import datetime
import numpy as np
from tqdm import tqdm
import re


###############################
# Functions
def read_sql_to_df(sql: str, dsn: str = 'EDWPROD') -> pd.DataFrame:
    conn = pyodbc.connect(dsn=dsn, autocommit=True, unicode_results=True)
    res = pd.read_sql(sql=sql, con=conn)
    conn.close()
    return res


def delete_sql_table(database_name: str, table_name: str, dsn: str = 'EDWPROD'):
    sql = f"""drop table {database_name}.{table_name}"""

    conn = pyodbc.connect(dsn=dsn, autocommit=True, unicode_results=True)
    cursor = conn.cursor()
    cursor.execute(sql)
    conn.commit()
    cursor.close()
    conn.close()

    print('Table Deleted')


def insert_df_into_sql_table(df: pd.DataFrame, database_name: str, table_name: str, dsn: str = 'EDWPROD'):
    column_names_list = df.columns.tolist()
    column_names_string = f'{column_names_list[0]}'
    question_marks = '?'
    for col in column_names_list[1:]:
        column_names_string += f', {col}'
        question_marks += ', ?'

    print(column_names_string)
    print(question_marks)
    conn = pyodbc.connect(dsn=dsn, autocommit=True, unicode_results=True)
    cursor = conn.cursor()
    cursor.executemany(f"""
    insert into {database_name}.{table_name} ({column_names_string})
    values ({question_marks})""", df.values.tolist())
    conn.commit()
    cursor.close()
    conn.close()

    print('All Lines Entered')


def check_if_table_exists(database_name: str, table_name: str, dsn: str = 'EDWPROD'):
    conn = pyodbc.connect(dsn=dsn, autocommit=True, unicode_results=True)
    sql = f"""SELECT 1 FROM dbc.TablesV WHERE databasename = '{database_name}' AND TABLENAME = '{table_name}'"""
    res = pd.read_sql(sql=sql, con=conn)
    if res.shape[0] == 0:
        table_exists = False
    else:
        table_exists = True

    conn.close()
    return table_exists


def execute_sql_code(sql: str, dsn: str = 'EDWPROD'):
    conn = pyodbc.connect(dsn=dsn, autocommit=True, unicode_results=True)
    cursor = conn.cursor()
    cursor.execute(sql)
    conn.commit()
    cursor.close()
    conn.close()
    print('Code Executed!')


class SOTKnowledgeCreation:
    def __init__(self, discover: str = 'MED', known: str = 'RX',
                 allow_known_to_equal_discover: bool = False,
                 include_base_dates: bool = False, include_office_cd: bool = False,
                 # office_cd_separate_from_carrier: bool = False,
                 include_prefix: bool = False, prefix_separate_from_carrier: bool = True,
                 blue_prefix_only: bool = True, include_prefix_dates: bool = True):
        """This class is used to create Source of Truth (SOT) tables for finding recommendations for carrier codes for
        specific coverage types based on data that is available under other coverage types.


        Initial Setup Variables
        discover: The carrier code coverage type you are looking to find recommendations for. Default is 'MED' for
        Medical.

        known: The carrier code coverage type you have data for and will use to find combinations of information to
         pinpoint recommendations. Default is 'RX' for Pharmacy.

        allow_known_to_equal_discover: In the case that the recommended carrier code can be the same as the carrier
        information that is being used to find the recommendation this can be switched to True. Default is False.

        include_base_dates: If the start date from the data that is being used to find the recommended carrier
        information is wanted, then the Minimum start date and Maximum start date will be shown. Default is False.

        include_office_cd: When the carrier office code for the discover carrier code should be included to find the
        best recommendation. Default is False.

        office_cd_separate_from_carrier: When the carrier office code for the discover carrier code should be treated
        as a secondary recommendation rather than as a combination of data. Default is False.

        include_prefix: When the policy number prefix for the discover carrier code should be included to find the best
        recommendation. Note that the prefix will be removed if it is determined to not be viable. Default is False.

        prefix_separate_from_carrier: When the policy number prefix for the discover carrier code should be treated as
        a secondary recommendation rather than as a combination of data. Will only be used if include_prefix is True.
        Default is True.

        blue_prefix_only: If the only prefixes that are needed are Blue Cross Blue Shield prefixes this should be True.
        Will only be used if include_prefix is True. Default is True.

        include_prefix_dates: This is the same as the include_base_dates but is specific to the prefixes for the
        recommendation rather than the carrier code. Will only be used if include_prefix is True and
        prefix_separate_from_carrier is True. Default is False.


        Additional Variables Available to Change
        num_emp_on_discover_min: The minimum number of people on a combination with the recommended carrier code to be
        potentially viable. Default is 25.

        num_emp_on_discover_prefix_min: The minimum number of people on a combination with the recommended carrier code
        and prefix to be potentially viable. Will only be used if include_prefix is True and
        prefix_separate_from_carrier is True. Default is 25.

        self_ratio_max: The ratio of people on a combination that have self relationship codes. This is useful to root
        out potential medicaid and medicare only populations. Default is 0.95.

        senior_ratio_max: The ratio of people on a combination that are senior citizens. This is useful to root out
        potential medicaid and medicare only populations. Default is 0.88.

        minor_ratio_max: The ratio of people on a combination that are minors. This is useful to root out potential
        medicaid only populations. Default is 0.8.

        days_for_cov_start_diff: . Default is 90.

        start_diff_ratio_max: The ratio of known and discover policy start dates that are longer than
        days_for_cov_start_diff. This is useful to root out unrelated connections between known and discover policies.
        Default is 0.8.

        max_prefix_length: The maximum allowed length of a prefix from a policy number. Will only be used if
        include_prefix is True. Default is 3.

        min_prefix_length: The minimum allowed length of a prefix from a policy number. Will only be used if
        include_prefix is True. Default is 1.

        max_bcbs_prefix_length: The maximum allowed length of a prefix from a Blue Cross Blue Shield policy number.
        This cannot be larger than max_prefix_length. Will only be used if include_prefix is True. Default is 3.

        min_bcbs_prefix_length: The minimum allowed length of a prefix from a Blue Cross Blue Shield policy number.
        This cannot be smaller than min_prefix_length. Will only be used if include_prefix is True. Default is 3.

        use_decimal_precision: The decimal precision used for storing data. Default is 4.

        display_decimal_precision: The decimal precision shown on the resulting table data. Default is 2.
        """

        # set when initializing
        self.__discover = discover
        self.__known = known
        self.allow_known_to_equal_discover = allow_known_to_equal_discover
        self.__include_base_dates = include_base_dates
        self.__include_office_cd = include_office_cd
        # self.office_cd_separate_from_carrier = office_cd_separate_from_carrier # Pursue this enhancement later
        self.__include_prefix = include_prefix
        self.__prefix_separate_from_carrier = prefix_separate_from_carrier
        self.blue_prefix_only = blue_prefix_only
        self.__include_prefix_dates = include_prefix_dates

        # Allowed Coverages
        self.allowed_coverages = ['MED', 'RX', 'DENT', 'VIS']

        # for Testing Use
        self.data_in_csv = False
        self.save_data = False
        self.starting_data_file_path = ('C:/Users/plight/OneDrive - Gainwell Technologies/Documents/'
                                        'Data Gap - Employer - Phoebe/SOT_K_P_Starting_Data.csv')
        self.small_sample = False
        self.small_sample_size = 4
        self.specify_discover_carriers = False
        self.specific_discover_carriers_df = pd.DataFrame({
            'REC_MED_CD': ['BCCA', '65978', 'BCNC', 'BCOH', 'BCNJ', '6111', 'BCMA', 'BCGA', 'BCVA', 'BCTN', '39026',
                           'EMPBC', 'BCAW', 'CNEXC', 'BCKY', 'BCMO', 'BCTX'],
            'TOTAL_RECORDS': [6648174, 3900656, 1507511, 1502324, 1328312, 1297577, 1243883, 1233790, 1125455, 1051886,
                              1021638, 927633, 888289, 733275, 660363, 640925, 634163]
        })
        self.specify_known_carriers = False
        self.specific_known_carriers_list = ['APM', 'RXOPT', 'NAVRX', 'MEDT', 'SWRLD', 'BCARD', 'MAXOR', '83253',
                                             'BCMSR', 'EHMRX', 'RXEDO', 'PRMRX', 'RXADV', 'CAPRX', 'RXM4D', 'MC21C',
                                             'PHBMG', '52189', 'PROCR', '76112', 'LEADM', 'AMHRX', 'AVIAP', 'RXAVI',
                                             'SCRPT', '24735', 'TRUEX', 'IPMRX', 'BMRRX', 'MAXCR', 'APPRX', 'EMPRX',
                                             'TRURX', 'PRORX', 'GMPRT', 'SSCRX', 'SMTRX', 'DREXI', 'USRRX']

        # set in general but editable
        self.num_emp_on_discover_min = 25
        self.num_emp_on_discover_prefix_min = 10
        self.self_ratio_max = 0.95
        self.senior_ratio_max = 0.88
        self.minor_ratio_max = 0.8
        self.days_for_cov_start_diff = 840  # 900 # 90
        self.start_diff_ratio_max = 0.8
        self.__max_prefix_length = 3
        self.__min_prefix_length = 1
        self.__max_bcbs_prefix_length = 3
        self.__min_bcbs_prefix_length = 3
        self.use_decimal_precision = 4
        self.__display_decimal_precision = 2

        # Changing BCBS Data - Note this implies that 1 letter Carrier Code of R is acceptable
        self.change_bcbs_fed_to_bcbs = False  # Changes federal bcbs carrier code to regular bcbs carrier code
        # (remove F) when there is a non-R prefix
        self.change_bcbs_to_bcbs_fed = False  # Changes regular bcbs carrier code to federal bcbs carrier code
        # (add F) when there is an R prefix

        # Random Variables
        self.empty_str = '-NA-'  # Used to fill any empty strings, such as for no recommended next carrier
        self.no_info_str = '-NOT PROVIDED-'  # Used to fill any empty provided information, such as Employer not
        # being provided
        self.no_next_suggestion = 'NO OTHER SUGGESTION FOR COMBINATION'

        # Initialize Various Variables and Dictionaries
        self.sot_columns_dict = self.__initialize_sot_columns_dictionary()
        self.initial_group_by_columns = self.__initialize_known_group_by_list()
        self.primary_discover_columns = self.__initialize_primary_discover_list()
        self.secondary_discover_columns = self.__initialize_secondary_discover_list()
        self.all_discover_columns = self.__initialize_all_discover_list()
        self.all_group_by_columns = self.__initialize_known_and_discover_list()
        self.agg_dict = self.__initialize_aggregate_dict()
        self.group_by_combos_list = self.__initialize_combo_list()

        # Lists of Removals
        self.remove_carrier_codes = ['', 'XXXXX']
        self.remove_source_codes = ['RS', 'V9']

        # Lists of Keeps
        self.keep_segment_types = ['013', '019']

        # List of Importance
        self.discover_importance_list = ['Carrier Code', 'Office Code', 'Prefix']  # Used for Ranking

        # Dictionary for when certain carrier codes should equal something else
        # Note the KEY is the original code and the VALUE is the new carrier code within the inner dictionaries
        self.carrier_code_change_dict = {'MED': {'UHCBH': '65978'},
                                         'RX': {},
                                         'DENT': {'UHCBH': '65978'},
                                         'VIS': {}}

        # Dictionary for when certain carrier codes need to be excluded from certain coverages,
        # mostly bc they are incorrectly being assigned to said coverage at some point in the process...
        self.carrier_code_exclusion_dict = {
            'KNOWN': {
                'MED': [],
                'RX': [],
                'DENT': [],
                'VIS': []
            },
            'DISCOVER': {
                'MED': [],
                'RX': [],
                'DENT': [],
                'VIS': []
            }
        }

        # Dictionary for Databases
        self.database_dict = {
            'TERADATA TABLES':
                {'NEDB': 'EDW_ELG_FL.NED_525',
                 'FUSP': 'EDW_ELG_FL.ARTFUSP',
                 'EMP': 'DL_Marshall.EMPLOYEES',
                 'PREF': 'DL_EMP_TBL.PREFIX_REF'},
            'CARRIER CODE':
                {'NEDB': 'CARRIER_CD',
                 'FUSP': 'CARRIER_CD',
                 'EMP': {'MED': 'MED_CARRIER_CD',
                         'RX': 'RX_CARRIER_CD',
                         'DENT': 'DENT_CARRIER_CD',
                         'VIS': 'VIS_CARRIER_CD'}},
            'CARRIER OFFICE CODE':
                {'NEDB': 'CARRIER_OFFICE_CD',
                 'FUSP': 'CARRIER_CD',
                 'EMP': {'MED': 'MED_CARRIER_OFFICE_CD',
                         'RX': 'RX_CARRIER_OFFICE_CD',
                         'DENT': 'DENT_CARRIER_OFFICE_CD',
                         'VIS': 'VIS_CARRIER_OFFICE_CD'}},
            'GROUP NUMBER':
                {'NEDB': 'GROUP_NUM',
                 'FUSP': 'GROUP_NUM',
                 'EMP': {'MED': 'MED_GROUP_NUM',
                         'RX': 'RX_GROUP_NUM',
                         'DENT': 'DENT_GROUP_NUM',
                         'VIS': 'VIS_GROUP_NUM'}},
            'PLAN NAME': {'FUSP': 'PLAN_NM'},
            'POLICY NUMBER':
                {'NEDB': 'POLICY_NUM',
                 'FUSP': 'POLICY_NUM',
                 'EMP': {'MED': 'MED_POLICY_NUM',
                         'RX': 'RX_POLICY_NUM',
                         'DENT': 'DENT_POLICY_NUM',
                         'VIS': 'VIS_POLICY_NUM'}},
            'EMPLOYER NAME':
                {'NEDB': 'EMPLOYER_NM',
                 'FUSP': 'EMP_NM',
                 'EMP': {'MED': 'MED_EMPLOYER',
                         'RX': 'RX_EMPLOYER',
                         'DENT': 'DENT_EMPLOYER',
                         'VIS': 'VIS_EMPLOYER'}},
            'INSURED FIRST NAME':
                {'NEDB': 'INSURED_FIRST_NM',
                 'FUSP': 'PH_FIRST_NM',
                 'EMP': 'INSURED_FIRST_NM'},
            'INSURED LAST NAME':
                {'NEDB': 'INSURED_LAST_NM',
                 'FUSP': 'PH_LAST_NM',
                 'EMP': 'INSURED_LAST_NM'},
            'INSURED SOCIAL SECURITY NUMBER':
                {'NEDB': 'INSURED_SSN_NUM',
                 'FUSP': 'PH_SSN_NUM',
                 'EMP': 'INSURED_SSN_NUM'},
            'INSURED BIRTH DATE':
                {'NEDB': 'INSURED_BIRTH_DT',
                 'FUSP': 'PH_DOB_DT',
                 'EMP': 'INSURED_BIRTH_DT'},
            'INSURED STATE CODE':
                {'NEDB': 'INSURED_STATE_CD',
                 'FUSP': 'PH_STATE_CD',
                 'EMP': 'INSURED_STATE_CD'},
            'DEPENDENT FIRST NAME':
                {'NEDB': 'DEPENDENT_FIRST_NM',
                 'FUSP': 'RECIP_FIRST_NM',
                 'EMP': 'DEPENDENT_FIRST_NM'},
            'DEPENDENT LAST NAME':
                {'NEDB': 'DEPENDENT_LAST_NM',
                 'FUSP': 'RECIP_LAST_NM',
                 'EMP': 'DEPENDENT_LAST_NM'},
            'DEPENDENT SOCIAL SECURITY NUMBER':
                {'NEDB': 'DEPENDENT_SSN_NUM',
                 'FUSP': 'RECIP_SSN_NUM',
                 'EMP': 'DEPENDENT_SSN_NUM'},
            'DEPENDENT BIRTH DATE':
                {'NEDB': 'DEPENDENT_BIRTH_DT',
                 'FUSP': 'RECIP_DOB_DT',
                 'EMP': 'DEPENDENT_BIRTH_DT'},
            'DEPENDENT MEDICAID NUMBER':
                {'NEDB': 'DEPENDENT_MEDICAID_NUM',
                 'FUSP': 'RECIP_MA_NUM',
                 'EMP': 'MA_NUM'},
            'POLICY START DATE':
                {'NEDB': {'MED': 'MED_ELIG_START_DT',
                          'RX': 'PHAR_ELIG_START_DT',
                          'DENT': 'DENTAL_ELIG_START_DT',
                          'VIS': 'VISION_ELIG_START_DT'},
                 'FUSP': 'POLICY_START_DT',
                 'EMP': {'MED': 'MED_COV_START',
                         'RX': 'RX_COV_START',
                         'DENT': 'DENT_COV_START',
                         'VIS': 'VIS_COV_START'}},
            'POLICY END DATE':
                {'NEDB': {'MED': 'MED_ELIG_STOP_DT',
                          'RX': 'PHAR_ELIG_STOP_DT',
                          'DENT': 'DENTAL_ELIG_STOP_DT',
                          'VIS': 'VISION_ELIG_STOP_DT'},
                 'FUSP': 'POLICY_END_DT',
                 'EMP': {'MED': 'MED_COV_END',
                         'RX': 'RX_COV_END',
                         'DENT': 'DENT_COV_END',
                         'VIS': 'VIS_COV_END'}},
            'SEGMENT TYPE CODE':
                {'NEDB': 'SEGMENT_TYPE_CD'},
            'ORIGINAL SOURCE CODE':
                {'NEDB': 'ORIG_SOURCE_CODE_CREATE_CD'},
            'POLICY TYPE CODE':
                {'FUSP': 'PLCTP_RF'},
            'PREFIX':
                {'PREF': 'BC_PREFIX'}
        }

    @property
    def known(self):
        return self.__known

    @known.setter
    def known(self, value):
        if value in self.allowed_coverages:
            self.__known = value
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.sot_columns_dict = self.__initialize_sot_columns_dictionary()
        else:
            print(f'{value} is not one of the allowed coverage types. '
                  f'Coverage types are: {str(self.allowed_coverages)[:]}')

    @property
    def discover(self):
        return self.__discover

    @discover.setter
    def discover(self, value):
        if value in self.allowed_coverages:
            self.__discover = value
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.sot_columns_dict = self.__initialize_sot_columns_dictionary()
        else:
            print(f'{value} is not one of the allowed coverage types. '
                  f'Coverage types are: {str(self.allowed_coverages)[:]}')

    @property
    def display_decimal_precision(self):
        return self.__discover

    @display_decimal_precision.setter
    def display_decimal_precision(self, value):
        if type(value) == int:
            self.__display_decimal_precision = value
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.sot_columns_dict = self.__initialize_sot_columns_dictionary()
        else:
            print(f'display_decimal_precision needs to be a number')

    def __initialize_sot_columns_dictionary(self):
        if self.__include_prefix:
            char_lim_for_info = 220
        else:
            char_lim_for_info = 100

        max_decimal_len = self.__display_decimal_precision + 2

        # for self.sot_columns_dict
        initial_dict = {
            # Used for Table
            'Row Number': {
                'Column Name': 'ROW_ID',
                'SQL Datatype': ('BIGINT GENERATED ALWAYS AS IDENTITY\n\t(START WITH 1\n\tINCREMENT BY 1\n\t'
                                 'MINVALUE 0\n\tMAXVALUE 999999999999999999\n\tNO CYCLE)'),
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': True, 'Order': -1},
                'Prefix': {'Keep': True, 'Order': -1},
                'Office Code': {'Keep': True, 'Order': -1},
                'Known Date and Office Code': {'Keep': True, 'Order': -1},
                'Prefix and Known Date': {'Keep': True, 'Order': -1},
                'Prefix and Prefix Date': {'Keep': True, 'Order': -1},
                'Prefix and Office Code': {'Keep': True, 'Order': -1},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': -1},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': -1},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': -1},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': -1},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Combo Number': {
                'Column Name': 'COMBO_ID',
                'SQL Datatype': 'BIGINT NOT NULL',
                'Base': {'Keep': True, 'Order': 0},
                'Known Date': {'Keep': True, 'Order': 0},
                'Prefix': {'Keep': True, 'Order': 0},
                'Office Code': {'Keep': True, 'Order': 0},
                'Known Date and Office Code': {'Keep': True, 'Order': 0},
                'Prefix and Known Date': {'Keep': True, 'Order': 0},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 0},
                'Prefix and Office Code': {'Keep': True, 'Order': 0},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 0},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 0},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 0},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 0},
                'Reference Table': {'Keep': True, 'Order': 0}},
            'Overall Rank': {
                'Column Name': f'RANK_OF_{self.__discover}',
                'SQL Datatype': 'INT',
                'Base': {'Keep': True, 'Order': 1},
                'Known Date': {'Keep': True, 'Order': 1},
                'Prefix': {'Keep': True, 'Order': 1},
                'Office Code': {'Keep': True, 'Order': 1},
                'Known Date and Office Code': {'Keep': True, 'Order': 1},
                'Prefix and Known Date': {'Keep': True, 'Order': 1},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 1},
                'Prefix and Office Code': {'Keep': True, 'Order': 1},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 1},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 1},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 1},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 1},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Prefix Rank': {
                'Column Name': f'RANK_OF_PREFIX',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 2},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 2},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 2},
                'Prefix and Office Code': {'Keep': True, 'Order': 2},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 2},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 2},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 2},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 2},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Recommended Carrier Code': {
                'Column Name': f'REC_{self.__discover}_CD',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': True, 'Order': 2},
                'Known Date': {'Keep': True, 'Order': 2},
                'Prefix': {'Keep': True, 'Order': 3},
                'Office Code': {'Keep': True, 'Order': 2},
                'Known Date and Office Code': {'Keep': True, 'Order': 2},
                'Prefix and Known Date': {'Keep': True, 'Order': 3},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 3},
                'Prefix and Office Code': {'Keep': True, 'Order': 3},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 3},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 3},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 3},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 3},
                'Reference Table': {'Keep': True, 'Order': 1}},
            'Recommended Carrier Office Code': {
                'Column Name': f'REC_{self.__discover}_OFFICE_CD',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': True, 'Order': 3},
                'Known Date and Office Code': {'Keep': True, 'Order': 3},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': True, 'Order': 4},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 4},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 4},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 4},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Recommended Prefix': {
                'Column Name': f'REC_{self.__discover}_PREFIX',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 4},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 4},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 4},
                'Prefix and Office Code': {'Keep': True, 'Order': 5},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 5},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 4},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 5},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 5},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Known Carrier Code': {
                'Column Name': f'{self.__known}_CARRIER_CD',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': True, 'Order': 3},
                'Known Date': {'Keep': True, 'Order': 3},
                'Prefix': {'Keep': True, 'Order': 5},
                'Office Code': {'Keep': True, 'Order': 4},
                'Known Date and Office Code': {'Keep': True, 'Order': 4},
                'Prefix and Known Date': {'Keep': True, 'Order': 5},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 5},
                'Prefix and Office Code': {'Keep': True, 'Order': 6},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 6},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 5},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 6},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 6},
                'Reference Table': {'Keep': True, 'Order': 2}},
            'Known Employer': {
                'Column Name': f'{self.__known}_EMPLOYER',
                'SQL Datatype': 'CHAR(20) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': True, 'Order': 4},
                'Known Date': {'Keep': True, 'Order': 4},
                'Prefix': {'Keep': True, 'Order': 6},
                'Office Code': {'Keep': True, 'Order': 5},
                'Known Date and Office Code': {'Keep': True, 'Order': 5},
                'Prefix and Known Date': {'Keep': True, 'Order': 6},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 6},
                'Prefix and Office Code': {'Keep': True, 'Order': 7},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 7},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 6},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 7},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 7},
                'Reference Table': {'Keep': True, 'Order': 3}},
            'Known Group Number': {
                'Column Name': f'{self.__known}_GROUP_NUM',
                'SQL Datatype': 'CHAR(20) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': True, 'Order': 5},
                'Known Date': {'Keep': True, 'Order': 5},
                'Prefix': {'Keep': True, 'Order': 7},
                'Office Code': {'Keep': True, 'Order': 6},
                'Known Date and Office Code': {'Keep': True, 'Order': 6},
                'Prefix and Known Date': {'Keep': True, 'Order': 7},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 7},
                'Prefix and Office Code': {'Keep': True, 'Order': 8},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 8},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 7},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 8},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 8},
                'Reference Table': {'Keep': True, 'Order': 4}},
            'Known State Code': {
                'Column Name': f'INSURED_STATE_CD',
                'SQL Datatype': 'CHAR(16) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': True, 'Order': 6},
                'Known Date': {'Keep': True, 'Order': 6},
                'Prefix': {'Keep': True, 'Order': 8},
                'Office Code': {'Keep': True, 'Order': 7},
                'Known Date and Office Code': {'Keep': True, 'Order': 7},
                'Prefix and Known Date': {'Keep': True, 'Order': 8},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 8},
                'Prefix and Office Code': {'Keep': True, 'Order': 9},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 9},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 8},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 9},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 9},
                'Reference Table': {'Keep': True, 'Order': 5}},
            'Total on Known Combination': {
                'Column Name': f'NUM_EMP_TOTAL',
                'SQL Datatype': 'INT',
                'Base': {'Keep': True, 'Order': 7},
                'Known Date': {'Keep': True, 'Order': 7},
                'Prefix': {'Keep': True, 'Order': 9},
                'Office Code': {'Keep': True, 'Order': 8},
                'Known Date and Office Code': {'Keep': True, 'Order': 8},
                'Prefix and Known Date': {'Keep': True, 'Order': 9},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 9},
                'Prefix and Office Code': {'Keep': True, 'Order': 10},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 10},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 9},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 10},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 10},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Total on Overall Combination': {
                'Column Name': f'NUM_EMP_ON_{self.__discover}',
                'SQL Datatype': 'INT',
                'Base': {'Keep': True, 'Order': 8},
                'Known Date': {'Keep': True, 'Order': 8},
                'Prefix': {'Keep': True, 'Order': 10},
                'Office Code': {'Keep': True, 'Order': 9},
                'Known Date and Office Code': {'Keep': True, 'Order': 9},
                'Prefix and Known Date': {'Keep': True, 'Order': 10},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 10},
                'Prefix and Office Code': {'Keep': True, 'Order': 11},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 11},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 10},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 11},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 11},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Total on Overall Combination plus Prefix': {
                'Column Name': f'NUM_EMP_ON_{self.__discover}_PREFIX',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 11},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 11},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 11},
                'Prefix and Office Code': {'Keep': True, 'Order': 12},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 12},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 11},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 12},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 12},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent on Overall Combination': {
                'Column Name': f'PER_EMP_ON_{self.__discover}',
                'SQL Datatype': f'DECIMAL({max_decimal_len},{self.__display_decimal_precision})',  # 'VARCHAR(21)',
                'Base': {'Keep': True, 'Order': 9},
                'Known Date': {'Keep': True, 'Order': 9},
                'Prefix': {'Keep': True, 'Order': 12},
                'Office Code': {'Keep': True, 'Order': 10},
                'Known Date and Office Code': {'Keep': True, 'Order': 10},
                'Prefix and Known Date': {'Keep': True, 'Order': 12},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 12},
                'Prefix and Office Code': {'Keep': True, 'Order': 13},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 13},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 12},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 13},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 13},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent of Shared Policy Numbers': {
                'Column Name': f'{self.__known}_{self.__discover}_POLICY_SHARE',
                'SQL Datatype': 'VARCHAR(21)',
                'Base': {'Keep': True, 'Order': 10},
                'Known Date': {'Keep': True, 'Order': 10},
                'Prefix': {'Keep': True, 'Order': 13},
                'Office Code': {'Keep': True, 'Order': 11},
                'Known Date and Office Code': {'Keep': True, 'Order': 11},
                'Prefix and Known Date': {'Keep': True, 'Order': 13},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 13},
                'Prefix and Office Code': {'Keep': True, 'Order': 14},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 14},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 13},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 14},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 14},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent on Overall Combination plus Prefix': {
                'Column Name': f'PER_EMP_ON_{self.__discover}_PREFIX',
                'SQL Datatype': 'VARCHAR(21)',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 14},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 14},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 14},
                'Prefix and Office Code': {'Keep': True, 'Order': 15},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 15},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 14},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 15},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 15},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent of Shared Policy Numbers on Prefix': {
                'Column Name': f'{self.__known}_{self.__discover}_POLICY_SHARE_ON_PREFIX',
                'SQL Datatype': 'VARCHAR(21)',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 15},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 15},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 15},
                'Prefix and Office Code': {'Keep': True, 'Order': 16},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 16},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 15},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 16},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 16},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Minimum Known Start Date': {
                'Column Name': f'MIN_{self.__known}_START_DT',
                'SQL Datatype': "DATE FORMAT 'YYYY-MM-DD'",
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': True, 'Order': 11},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': True, 'Order': 12},
                'Prefix and Known Date': {'Keep': True, 'Order': 16},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': True, 'Order': 17},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 17},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 16},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 17},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Maximum Known Start Date': {
                'Column Name': f'MAX_{self.__known}_START_DT',
                'SQL Datatype': "DATE FORMAT 'YYYY-MM-DD'",
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': True, 'Order': 12},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': True, 'Order': 13},
                'Prefix and Known Date': {'Keep': True, 'Order': 17},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': True, 'Order': 18},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 18},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 17},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 18},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Minimum Prefix Start Date': {
                'Column Name': f'MIN_PREFIX_START_DT',
                'SQL Datatype': "DATE FORMAT 'YYYY-MM-DD'",
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 16},
                'Prefix and Office Code': {'Keep': True, 'Order': 17},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 18},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 18},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 19},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Maximum Prefix Start Date': {
                'Column Name': f'MAX_PREFIX_START_DT',
                'SQL Datatype': "DATE FORMAT 'YYYY-MM-DD'",
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 17},
                'Prefix and Office Code': {'Keep': True, 'Order': 18},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 19},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 19},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 20},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Top Prefix for Carrier': {
                'Column Name': f'TOP_{self.__discover}_PREFIX',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 16},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 18},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 18},
                'Prefix and Office Code': {'Keep': True, 'Order': 19},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 19},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 20},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 19},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 21},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Next Recommended Prefix for Carrier': {
                'Column Name': f'NEXT_REC_PREFIX',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 17},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 19},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 19},
                'Prefix and Office Code': {'Keep': True, 'Order': 20},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 20},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 21},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 20},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 22},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Information for Next Recommended Prefix': {
                'Column Name': f'NEXT_PREFIX_INFO',
                'SQL Datatype': 'VARCHAR(105)',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 18},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': True, 'Order': 20},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 20},
                'Prefix and Office Code': {'Keep': True, 'Order': 21},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 21},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 22},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 21},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 23},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Next Recommended Carrier Code': {
                'Column Name': f'NEXT_REC_{self.__discover}_CD',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': True, 'Order': 11},
                'Known Date': {'Keep': True, 'Order': 13},
                'Prefix': {'Keep': True, 'Order': 19},
                'Office Code': {'Keep': True, 'Order': 12},
                'Known Date and Office Code': {'Keep': True, 'Order': 14},
                'Prefix and Known Date': {'Keep': True, 'Order': 21},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 21},
                'Prefix and Office Code': {'Keep': True, 'Order': 22},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 22},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 23},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 22},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 24},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Next Recommended Carrier Office Code': {
                'Column Name': f'NEXT_REC_{self.__discover}_OFFICE_CD',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': True, 'Order': 13},
                'Known Date and Office Code': {'Keep': True, 'Order': 15},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': True, 'Order': 23},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 23},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 23},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 25},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Recommended Prefix for Next Carrier': {
                'Column Name': f'NEXT_REC_{self.__discover}_PREFIX',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': True, 'Order': 20},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': True, 'Order': 16},
                'Prefix and Known Date': {'Keep': True, 'Order': 22},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 22},
                'Prefix and Office Code': {'Keep': True, 'Order': 24},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 24},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 24},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 24},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 26},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Information for Next Recommended Carrier Code': {
                'Column Name': f'NEXT_{self.__discover}_INFO',
                'SQL Datatype': f'VARCHAR({char_lim_for_info})',
                'Base': {'Keep': True, 'Order': 12},
                'Known Date': {'Keep': True, 'Order': 14},
                'Prefix': {'Keep': True, 'Order': 21},
                'Office Code': {'Keep': True, 'Order': 14},
                'Known Date and Office Code': {'Keep': True, 'Order': 17},
                'Prefix and Known Date': {'Keep': True, 'Order': 23},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 23},
                'Prefix and Office Code': {'Keep': True, 'Order': 25},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 25},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 25},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 25},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 27},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Potential Medicare Population Gap': {
                'Column Name': f'POTENTIAL_MA_GAP',
                'SQL Datatype': 'INT',
                'Base': {'Keep': True, 'Order': 13},
                'Known Date': {'Keep': True, 'Order': 13},
                'Prefix': {'Keep': True, 'Order': 22},
                'Office Code': {'Keep': True, 'Order': 15},
                'Known Date and Office Code': {'Keep': True, 'Order': 18},
                'Prefix and Known Date': {'Keep': True, 'Order': 24},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 24},
                'Prefix and Office Code': {'Keep': True, 'Order': 26},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 26},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 26},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 26},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 28},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Table Create Date': {
                'Column Name': f'CREATE_DT',
                'SQL Datatype': "DATE FORMAT 'YYYY-MM-DD'",
                'Base': {'Keep': True, 'Order': 14},
                'Known Date': {'Keep': True, 'Order': 14},
                'Prefix': {'Keep': True, 'Order': 23},
                'Office Code': {'Keep': True, 'Order': 16},
                'Known Date and Office Code': {'Keep': True, 'Order': 19},
                'Prefix and Known Date': {'Keep': True, 'Order': 25},
                'Prefix and Prefix Date': {'Keep': True, 'Order': 25},
                'Prefix and Office Code': {'Keep': True, 'Order': 27},
                'Prefix, Known Date, and Office Code': {'Keep': True, 'Order': 27},
                'Prefix, Known Date, and Prefix Date': {'Keep': True, 'Order': 27},
                'Prefix, Prefix Date, and Office Code': {'Keep': True, 'Order': 27},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': True, 'Order': 29},
                'Reference Table': {'Keep': False, 'Order': None}},

            # Only used for Calculations
            'Count of Self Policies': {
                'Column Name': 'SELF_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Seniors': {
                'Column Name': 'SENIOR_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Minors': {
                'Column Name': 'MINOR_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Unrelated Start Dates': {
                'Column Name': 'START_DIFF_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Shared Policy Numbers': {
                'Column Name': f'{self.__known}_{self.__discover}_POLICY_SHARE_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Shared Policy Numbers on Prefix': {
                'Column Name': f'PREFIX_{self.__known}_{self.__discover}_POLICY_SHARE_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Shared Policy Numbers on Office Code': {
                'Column Name': f'OFFICE_CODE_{self.__known}_{self.__discover}_POLICY_SHARE_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Count of Individual Records': {
                'Column Name': f'RECORD_CNT',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent Ceiling of Shared Policy Numbers': {
                'Column Name': f'PER_{self.__known}_{self.__discover}_POLICY_SHARE_CEILING',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent Ceiling of Shared Policy Numbers on Prefix': {
                'Column Name': f'PER_PREFIX_{self.__known}_{self.__discover}_POLICY_SHARE_CEILING',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent Ceiling of Shared Policy Numbers on Office Code': {
                'Column Name': f'PER_OFFICE_CODE_{self.__known}_{self.__discover}_POLICY_SHARE_CEILING',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent Ceiling on Overall Combination': {
                'Column Name': f'PER_EMP_ON_{self.__discover}_CEILING',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Percent Ceiling on Overall Combination plus Prefix': {
                'Column Name': f'PER_EMP_ON_{self.__discover}_PREFIX_Ceiling',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Column Selection Letter': {
                'Column Name': f'COLUMN_SELECTION',
                'SQL Datatype': 'CHAR(10) CHARACTER SET LATIN CASESPECIFIC',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Column Selection Length': {
                'Column Name': f'COLUMN_SELECTION_LENGTH',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Column Selection Priority': {
                'Column Name': f'COLUMN_SELECTION_PRIORITY',
                'SQL Datatype': 'INT',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}},
            'Column Selection Concatenation': {
                'Column Name': f'COLUMN_SELECTION_CONCAT',
                'SQL Datatype': 'VARCHAR(80)',
                'Base': {'Keep': False, 'Order': None},
                'Known Date': {'Keep': False, 'Order': None},
                'Prefix': {'Keep': False, 'Order': None},
                'Office Code': {'Keep': False, 'Order': None},
                'Known Date and Office Code': {'Keep': False, 'Order': None},
                'Prefix and Known Date': {'Keep': False, 'Order': None},
                'Prefix and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, and Prefix Date': {'Keep': False, 'Order': None},
                'Prefix, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Prefix, Known Date, Prefix Date, and Office Code': {'Keep': False, 'Order': None},
                'Reference Table': {'Keep': False, 'Order': None}}
        }
        return initial_dict

    def __create_set_string(self):
        set_list = list()
        if self.__include_prefix:
            set_list.append('Prefix')
        if self.__include_base_dates:
            set_list.append('Known Date')
        if self.__include_prefix_dates and self.__include_prefix:
            set_list.append('Prefix Date')
        if self.__include_office_cd:
            set_list.append('Office Code')
        print(f'Set List: {set_list}')

        set_list_len = len(set_list)
        if set_list_len == 0:
            set_string = 'Base'
        else:
            set_string = f'{set_list[0]}'
            if set_list_len > 1:
                if set_list_len > 2:
                    set_string += ', '
                    for item in set_list[1:-1]:
                        set_string += f' {item},'
                set_string += f' and {set_list[-1]}'

        return set_string

    @property
    def include_office_cd(self):
        return self.__include_office_cd

    @include_office_cd.setter
    def include_office_cd(self, value):
        if value is True or value is False or value == 1 or value == 0:
            self.__include_office_cd = bool(value)
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.primary_discover_columns = self.__initialize_primary_discover_list()
            # self.secondary_discover_columns = self.__initialize_secondary_discover_list()
            self.all_discover_columns = self.__initialize_all_discover_list()
            self.all_group_by_columns = self.__initialize_known_and_discover_list()
        else:
            print(f'include_office_cd requires a Boolean value. '
                  f'Please enter one of the following acceptable variables: True, 1, False, or 0')

    @property
    def include_base_dates(self):
        return self.__include_base_dates

    @include_base_dates.setter
    def include_base_dates(self, value):
        if value is True or value is False or value == 1 or value == 0:
            self.__include_base_dates = bool(value)
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.agg_dict = self.__initialize_aggregate_dict()
        else:
            print(f'include_base_dates requires a Boolean value. '
                  f'Please enter one of the following acceptable variables: True, 1, False, or 0')

    @property
    def include_prefix(self):
        return self.__include_prefix

    @include_prefix.setter
    def include_prefix(self, value):
        if value is True or value is False or value == 1 or value == 0:
            self.__include_prefix = bool(value)
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.sot_columns_dict = self.__initialize_sot_columns_dictionary()
            self.agg_dict = self.__initialize_aggregate_dict()
            self.primary_discover_columns = self.__initialize_primary_discover_list()
            self.secondary_discover_columns = self.__initialize_secondary_discover_list()
            self.all_discover_columns = self.__initialize_all_discover_list()
            self.all_group_by_columns = self.__initialize_known_and_discover_list()
        else:
            print(f'include_prefix requires a Boolean value. '
                  f'Please enter one of the following acceptable variables: True, 1, False, or 0')

    @property
    def prefix_separate_from_carrier(self):
        return self.__prefix_separate_from_carrier

    @prefix_separate_from_carrier.setter
    def prefix_separate_from_carrier(self, value):
        if value is True or value is False or value == 1 or value == 0:
            self.__prefix_separate_from_carrier = bool(value)
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.primary_discover_columns = self.__initialize_primary_discover_list()
            self.secondary_discover_columns = self.__initialize_secondary_discover_list()
            self.all_discover_columns = self.__initialize_all_discover_list()
            self.all_group_by_columns = self.__initialize_known_and_discover_list()
        else:
            print(f'prefix_separate_from_carrier requires a Boolean value. '
                  f'Please enter one of the following acceptable variables: True, 1, False, or 0')

    @property
    def include_prefix_dates(self):
        return self.__include_prefix_dates

    @include_prefix_dates.setter
    def include_prefix_dates(self, value):
        if value is True or value is False or value == 1 or value == 0:
            self.__include_prefix_dates = bool(value)
            # When var1 is updated, reinitialize the dictionary based on the updated values.
            self.agg_dict = self.__initialize_aggregate_dict()
        else:
            print(f'include_prefix_dates requires a Boolean value. '
                  f'Please enter one of the following acceptable variables: True, 1, False, or 0')

    def __initialize_known_group_by_list(self):
        known_group_by_list = [self.sot_columns_dict['Known Carrier Code']['Column Name'],
                               self.sot_columns_dict['Known Employer']['Column Name'],
                               self.sot_columns_dict['Known Group Number']['Column Name'],
                               self.sot_columns_dict['Known State Code']['Column Name']]

        return known_group_by_list

    def __initialize_primary_discover_list(self):
        column_list = [self.sot_columns_dict['Recommended Carrier Code']['Column Name']]

        if self.__include_prefix and not self.__prefix_separate_from_carrier:
            column_list.append(self.sot_columns_dict['Recommended Prefix']['Column Name'])

        if self.__include_office_cd:
            column_list.append(self.sot_columns_dict['Recommended Carrier Office Code']['Column Name'])

        return column_list

    def __initialize_secondary_discover_list(self):
        column_list = []

        if self.__include_prefix and self.__prefix_separate_from_carrier:
            column_list.append(self.sot_columns_dict['Recommended Prefix']['Column Name'])

        # if self.__include_office_cd and self.office_cd_separate_from_carrier:
        #    columns_list.append(self.sot_columns_dict['Recommended Carrier Office Code']['Column Name'])

        return column_list

    def __initialize_all_discover_list(self):
        column_list = self.primary_discover_columns[:] + self.secondary_discover_columns[:]

        return column_list

    def __initialize_known_and_discover_list(self):
        column_list = self.all_discover_columns[:] + self.initial_group_by_columns[:]

        return column_list

    def __initialize_combo_list(self):
        # Create Combo List
        combo_list = []
        for r in range(len(self.initial_group_by_columns), 0, -1):
            combinations_r = combinations(self.initial_group_by_columns, r)
            combo_list.extend([list(tup) for tup in combinations_r])

        return combo_list

    def __initialize_aggregate_dict(self):
        aggregate_dict = {self.sot_columns_dict['Count of Self Policies']['Column Name']: 'sum',
                          self.sot_columns_dict['Count of Seniors']['Column Name']: 'sum',
                          self.sot_columns_dict['Count of Minors']['Column Name']: 'sum',
                          self.sot_columns_dict['Count of Unrelated Start Dates']['Column Name']: 'sum',
                          self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name']: 'sum',
                          self.sot_columns_dict['Count of Individual Records']['Column Name']: 'sum'}

        if self.__include_base_dates or (self.__include_prefix and self.__include_prefix_dates):
            aggregate_dict['MIN_START_DT'] = 'min'
            aggregate_dict['MAX_START_DT'] = 'max'

        return aggregate_dict

    @property
    def max_prefix_length(self):
        return self.__max_prefix_length

    @max_prefix_length.setter
    def max_prefix_length(self, value):
        if value >= self.__min_prefix_length:
            self.__max_prefix_length = value
            if self.__max_prefix_length < self.__max_bcbs_prefix_length:
                self.__max_bcbs_prefix_length = self.__max_prefix_length
                print(f'max_bcbs_prefix_length was changed to be equal to max_prefix_length')
            if self.__max_prefix_length < self.__min_bcbs_prefix_length:
                self.__min_bcbs_prefix_length = self.__max_prefix_length
                print(f'min_bcbs_prefix_length was changed to be equal to max_prefix_length')
        else:
            print(f'max_prefix_length cannot be changed to be a lower value than min_prefix_length')

    @property
    def min_prefix_length(self):
        return self.__min_prefix_length

    @min_prefix_length.setter
    def min_prefix_length(self, value):
        if value <= self.__max_prefix_length:
            self.__min_prefix_length = value
            if self.__min_prefix_length > self.__min_bcbs_prefix_length:
                self.__min_bcbs_prefix_length = self.__min_prefix_length
                print(f'min_bcbs_prefix_length was changed to be equal to min_prefix_length')
            if self.__min_prefix_length > self.__max_bcbs_prefix_length:
                self.__max_bcbs_prefix_length = self.__min_prefix_length
                print(f'max_bcbs_prefix_length was changed to be equal to min_prefix_length')
        else:
            print(f'min_prefix_length cannot be changed to be a higher value than max_prefix_length')

    @property
    def max_bcbs_prefix_length(self):
        return self.__max_bcbs_prefix_length

    @max_bcbs_prefix_length.setter
    def max_bcbs_prefix_length(self, value):
        if self.__min_prefix_length >= value >= self.__min_bcbs_prefix_length:
            self.__max_bcbs_prefix_length = value
        else:
            print(f'max_bcbs_prefix_length cannot be changed to be a lower value than min_bcbs_prefix_length or a '
                  f'higher value than max_prefix_length')

    @property
    def min_bcbs_prefix_length(self):
        return self.__min_bcbs_prefix_length

    @min_bcbs_prefix_length.setter
    def min_bcbs_prefix_length(self, value):
        if self.__max_bcbs_prefix_length >= value >= self.__min_prefix_length:
            self.__min_bcbs_prefix_length = value
        else:
            print(f'min_bcbs_prefix_length cannot be changed to be a higher value than max_bcbs_prefix_length or a '
                  f'lower value than min_prefix_length')

    @staticmethod
    def __create_sql_list(provided_list: list):
        return_string = "("
        for item in provided_list:
            if return_string == "(":
                return_string += f"'{item}'"
            else:
                return_string += f", '{item}'"
        return_string += ")"
        return return_string

    def __bcbs_carrier_cd_check(self, row):
        carrier_code = row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']]

        if re.match(r'(BC)|(BSC)|(USABL)', carrier_code):
            return True
        else:
            return False

    @staticmethod
    def __strip_objects_clean(df: pd.DataFrame):
        column_list = list(df.columns)
        for col in column_list:
            if df.dtypes[col] == 'object':
                try:
                    df[col] = df[col].str.strip()
                finally:
                    continue

        print('Formatting Complete!')
        return df

    def __fusp_medicare_filter(self):
        """Create the filter that will be used to remove data that is medicare/medicade based on FUSP data"""
        return_string = f"""
UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT IN ('LABYHP', 'NJFAMCAR', 'NYCDFHP', 'TNDSNP', 'MIPHCP',
    'MM01', 'KJ2A', 'L57A', 'PHMEDCD', 'ARMCD000', 'COMCD000','EBSCOMMCDHP', 'EBSPPMCDHP', 'FCHPMCD', 
    'GAMCD000', 'HAPMCD', 'IAMCD000', 'INMCDWP0', 'LAMCD000', 'MCDERMO', 'MDMCD000', 'MNMCDBBS',
    'MOMCD000', 'NCMCD000', 'NEMCD001','NJMCD000', 'NVMCD000', 'NYMCD000', 'NYMCDWNY', 
    'OHMCD001', 'OMCDTWP', 'P32HMCDMA', 'P32HMCDRI', 'RXMCD99', 'TNMCD000', 'TXMCD000', 
    'VAMCDWP0', 'WAMCD000', 'WAMCD001', 'WCFLMCD', 'WCGAMCD', 'WCHIMCD', 'WCILMCD', 'WCKYMCD',
    'WCNJMCD', 'WCNYMCD', 'WCSCMCD', 'WCZBHMCD', 'WIMCDWP0')
AND UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT LIKE '%HCP'
AND UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT LIKE '%DSNP'
AND UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT LIKE 'FLMCD%'
AND UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT LIKE 'KYMCD%'
AND UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT LIKE 'TNMCD%'
AND UPPER(TRIM({self.database_dict['GROUP NUMBER']['FUSP']})) NOT LIKE '%CAID%'
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) <> 'HEALTHY OPTIONS'
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) NOT LIKE '%MCAID%'
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) <> 'SILVERSCRIPT-INDIV-E'
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) not like 'MA PLANS%'
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) <> 'COA PLUS'
--2023-07 REMOVED MCA, MCB, MCSUP FROM POLICY TYPE EXCLUSIONS
AND UPPER(TRIM({self.database_dict['POLICY TYPE CODE']['FUSP']})) NOT IN ('MAMCO', 'CHIP','RXCARD', 'RXMAIL', 'COBRA', 
    'CANONLY', 'CANONLYRX', 'DIABSUPPLY', 'LTCONLY', 'LTDONLY', 'MISSING')
-- 2022-12-21 Modified, added null handling, wasn't selecting any where plan_nm is null previously
-- 2023-07 Removed {self.database_dict['PLAN NAME']['FUSP']} LIKE '%MEDICARE%' to allow Medicare policies through
AND ((UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%MEDICAI%'
    AND UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%DSNP%'
    AND UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%CHIP%'
    AND UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%MEDADV%'
    AND UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%MED ADV%'
    AND UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%MMC%'
    AND UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) NOT LIKE '%HARP%')
    OR UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) IS NULL
    OR UPPER(TRIM({self.database_dict['PLAN NAME']['FUSP']})) = '')
-- 2023-07 ALLOW MEDICARE POLICIES THROUGH
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) NOT LIKE '%MEDICAI%'
AND UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) NOT LIKE '%DSNP%'
AND (UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) NOT LIKE '%CHIP%'
--2023-07 Allow Chipotle policies, was being excluded by %CHIP%
    OR UPPER(TRIM({self.database_dict['EMPLOYER NAME']['FUSP']})) LIKE '%CHIPOTLE%')"""
        return return_string

    def sql_for_carriers(self):
        """Create the SQL to determine what carrier codes to use for the Discover carrier codes"""
        # String for if the known carrier code cannot be the same as the discover carrier code
        if self.allow_known_to_equal_discover:
            known_equals_discover_str = ''
        else:
            known_equals_discover_str = (f"AND EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} <> "
                                         f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]}")

        # Discover Carrier Code String
        if len(self.carrier_code_change_dict[self.__discover]) != 0:
            discover_carrier_cd_str = "Case "
            for key, value in self.carrier_code_change_dict[self.__discover].items():
                discover_carrier_cd_str += (f"when EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} = "
                                            f"'{key}' then '{value}' ")
            discover_carrier_cd_str += (f"else EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} end "
                                        f"as {self.sot_columns_dict['Recommended Carrier Code']['Column Name']}")
        else:
            discover_carrier_cd_str = (f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} as "
                                       f"{self.sot_columns_dict['Recommended Carrier Code']['Column Name']}")
        print(discover_carrier_cd_str)

        # If doing a small sample
        if self.small_sample:
            small_sample_string = f'top {self.small_sample_size} '
        else:
            small_sample_string = ''

        # Remove Carrier Code Strings
        if len(self.carrier_code_exclusion_dict['KNOWN'][self.__known]) > 0:
            known_carrier_list_str = self.__create_sql_list(
                self.carrier_code_exclusion_dict['KNOWN'][self.__known] + self.remove_carrier_codes)
            known_carrier_code_removal = \
                f"""AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} IS NOT NULL
    AND EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} NOT IN {known_carrier_list_str}"""
        else:
            known_carrier_list_str = self.__create_sql_list(self.remove_carrier_codes)
            known_carrier_code_removal = \
                f"""AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} IS NOT NULL 
    AND TRIM(EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]}) NOT IN {known_carrier_list_str})"""

        if len(self.carrier_code_exclusion_dict['DISCOVER'][self.__discover]) > 0:
            discover_carrier_list_str = self.__create_sql_list(
                self.carrier_code_exclusion_dict['DISCOVER'][self.__discover] + self.remove_carrier_codes)
            discover_carrier_code_removal = \
                f"""AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} IS NOT NULL
    AND EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} NOT IN {discover_carrier_list_str}"""
        else:
            discover_carrier_list_str = self.__create_sql_list(self.remove_carrier_codes)
            discover_carrier_code_removal = \
                f"""AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} IS NOT NULL 
    AND TRIM(EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]}) NOT IN {discover_carrier_list_str})"""

        # Sql String
        return_string = f"""
select {small_sample_string}{discover_carrier_cd_str}, 
    Count(*) as TOTAL_RECORDS
from {self.database_dict['TERADATA TABLES']['EMP']} as EMP
Left JOIN 
    (Select {self.database_dict['CARRIER CODE']['FUSP']}, 
        {self.database_dict['INSURED FIRST NAME']['FUSP']}, 
        {self.database_dict['INSURED LAST NAME']['FUSP']}, 
        {self.database_dict['INSURED SOCIAL SECURITY NUMBER']['FUSP']}, 
        {self.database_dict['INSURED BIRTH DATE']['FUSP']}, 
        {self.database_dict['DEPENDENT FIRST NAME']['FUSP']}, 
        {self.database_dict['DEPENDENT LAST NAME']['FUSP']}, 
        {self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['FUSP']}, 
        {self.database_dict['DEPENDENT BIRTH DATE']['FUSP']}, 
        {self.database_dict['POLICY START DATE']['FUSP']}
    from {self.database_dict['TERADATA TABLES']['FUSP']}
    WHERE {self.__fusp_medicare_filter()}
    ) as F ON ((EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} = F.{self.database_dict['CARRIER CODE']['FUSP']} 
                AND EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__discover]} = F.{self.database_dict['POLICY START DATE']['FUSP']}) 
            OR (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} = F.{self.database_dict['CARRIER CODE']['FUSP']} 
                AND EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__known]} = F.{self.database_dict['POLICY START DATE']['FUSP']})) 
        AND F.{self.database_dict['INSURED FIRST NAME']['FUSP']} = EMP.{self.database_dict['INSURED FIRST NAME']['EMP']}
        AND F.{self.database_dict['INSURED LAST NAME']['FUSP']} = EMP.{self.database_dict['INSURED LAST NAME']['EMP']}
        AND F.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['FUSP']} = EMP.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['EMP']}
        AND F.{self.database_dict['INSURED BIRTH DATE']['FUSP']} = EMP.{self.database_dict['INSURED BIRTH DATE']['EMP']}
        AND F.{self.database_dict['DEPENDENT FIRST NAME']['FUSP']} = EMP.{self.database_dict['DEPENDENT FIRST NAME']['EMP']}
        AND F.{self.database_dict['DEPENDENT LAST NAME']['FUSP']} = EMP.{self.database_dict['DEPENDENT LAST NAME']['EMP']}
        AND F.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['FUSP']} = EMP.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['EMP']}
        AND F.{self.database_dict['DEPENDENT BIRTH DATE']['FUSP']} = EMP.{self.database_dict['DEPENDENT BIRTH DATE']['EMP']}
where {self.database_dict['POLICY START DATE']['EMP'][self.__known]} is not null 
    and {self.database_dict['POLICY START DATE']['EMP'][self.__discover]} is not null
    {known_carrier_code_removal}
    {discover_carrier_code_removal}
    {known_equals_discover_str}
    AND (F.{self.database_dict['CARRIER CODE']['FUSP']} is null 
        AND F.{self.database_dict['POLICY START DATE']['FUSP']} is null 
        AND F.{self.database_dict['INSURED FIRST NAME']['FUSP']} is null 
        AND F.{self.database_dict['INSURED LAST NAME']['FUSP']} is null 
        AND F.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['FUSP']} is null 
        AND F.{self.database_dict['INSURED BIRTH DATE']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT FIRST NAME']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT LAST NAME']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT BIRTH DATE']['FUSP']} is null) -- Join Conditions Excluded
GROUP BY 1
ORDER BY 2 desc,1
"""
        return return_string

    def sql_for_data(self, discover_carrier_code_list: list = None):
        """Create the SQL to collect the initial data used in the code"""
        if self.__include_prefix:
            prefix_string = (f" case when TO_NUMBER(SUBSTR(oreplace("
                             f"EMP.{self.database_dict['POLICY NUMBER']['EMP'][self.__known]},' ',''),1,3)) is null "
                             f"and\n\tTO_NUMBER(SUBSTR(oreplace("
                             f"EMP.{self.database_dict['POLICY NUMBER']['EMP'][self.__known]},' ',''),1,1)) is null "
                             f"then SUBSTR(oreplace("
                             f"EMP.{self.database_dict['POLICY NUMBER']['EMP'][self.__known]},' ',''),1,"
                             f"{self.__max_prefix_length})\n\telse '' end as "
                             f"{self.sot_columns_dict['Recommended Prefix']['Column Name']},")
            prefix_group_by_num = ',6'
        else:
            prefix_string = f""" """
            prefix_group_by_num = ''

        if (self.__include_prefix_dates and self.__include_prefix) or self.__include_base_dates:
            date_string = f""" MIN({self.database_dict['POLICY START DATE']['EMP'][self.__known]}) as MIN_START_DT, 
MAX({self.database_dict['POLICY START DATE']['EMP'][self.__known]}) as MAX_START_DT,"""
        else:
            date_string = ''

        if self.allow_known_to_equal_discover:
            known_equals_discover_str = ''
        else:
            known_equals_discover_str = (f"AND EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} <> "
                                         f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]}")

        if len(self.carrier_code_change_dict[self.__discover]) != 0:
            discover_carrier_cd_str = "Case "
            for key, value in self.carrier_code_change_dict[self.__discover].items():
                discover_carrier_cd_str += (f"when EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} = "
                                            f"'{key}' then '{value}' ")
            discover_carrier_cd_str += (f"else EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} end as "
                                        f"{self.sot_columns_dict['Recommended Carrier Code']['Column Name']},")
        else:
            discover_carrier_cd_str = (f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} as "
                                       f"{self.sot_columns_dict['Recommended Carrier Code']['Column Name']},")

        if self.__include_office_cd:
            emp_office_cd_str = (f"EMP.{self.database_dict['CARRIER OFFICE CODE']['EMP'][self.__discover]} as "
                                 f"{self.sot_columns_dict['Recommended Carrier Office Code']['Column Name']},")
            if self.__include_prefix:
                office_group_by_num = ', 7'
            else:
                office_group_by_num = ', 6'
        else:
            emp_office_cd_str = ''
            office_group_by_num = ''

        # Remove Carrier Code String
        general_carrier_code_removal = self.__create_sql_list(self.remove_carrier_codes)

        # Filter Discover Carrier Codes
        if discover_carrier_code_list is not None and len(
                self.carrier_code_exclusion_dict['DISCOVER'][self.__discover]) > 0:
            for item in self.carrier_code_exclusion_dict['DISCOVER'][self.__discover]:
                if item in discover_carrier_code_list:
                    discover_carrier_code_list.remove(item)
            for item in self.remove_carrier_codes:
                if item in discover_carrier_code_list:
                    discover_carrier_code_list.remove(item)
            if len(discover_carrier_code_list) == 0:
                discover_carrier_code_list = None

        if discover_carrier_code_list is not None:
            discover_carrier_code_str = self.__create_sql_list(discover_carrier_code_list)
            filter_discover_carrier_code_str = (f"AND EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} "
                                                f"IN {discover_carrier_code_str}")
        elif len(self.carrier_code_exclusion_dict['DISCOVER'][self.__discover]) > 0:
            discover_carrier_list_str = self.__create_sql_list(
                self.carrier_code_exclusion_dict['DISCOVER'][self.__discover] + self.remove_carrier_codes)
            filter_discover_carrier_code_str = (f"AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]}"
                                                f" IS NOT NULL\n\tAND "
                                                f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} NOT "
                                                f"IN {discover_carrier_list_str})")
        else:
            discover_carrier_list_str = self.__create_sql_list(self.remove_carrier_codes)
            filter_discover_carrier_code_str = (f"AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]}"
                                                f" IS NOT NULL\n\tAND TRIM("
                                                f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]}) "
                                                f"NOT IN {discover_carrier_list_str})")

        # Filter Known Carrier Codes
        if self.specify_known_carriers and len(self.specific_known_carriers_list) > 0:
            known_carriers_list = self.specific_known_carriers_list
            for item in self.carrier_code_exclusion_dict['KNOWN'][self.__known]:
                if item in known_carriers_list:
                    known_carriers_list.remove(item)
            for item in self.remove_carrier_codes:
                if item in known_carriers_list:
                    known_carriers_list.remove(item)
            if len(known_carriers_list) == 0:
                known_carriers_list = None
        else:
            known_carriers_list = None

        if known_carriers_list is not None:
            known_carrier_code_str = self.__create_sql_list(known_carriers_list)
            filter_known_carrier_code_str = (f"AND EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} IN "
                                             f"{known_carrier_code_str}")
        elif len(self.carrier_code_exclusion_dict['KNOWN'][self.__known]) > 0:
            known_carrier_list_str = self.__create_sql_list(
                self.carrier_code_exclusion_dict['KNOWN'][self.__known] + self.remove_carrier_codes)
            filter_known_carrier_code_str = (f"AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} IS "
                                             f"NOT NULL\n\tAND "
                                             f"EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} NOT "
                                             f"IN {known_carrier_list_str})")
        else:
            known_carrier_list_str = self.__create_sql_list(self.remove_carrier_codes)
            filter_known_carrier_code_str = (f"AND (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} IS "
                                             f"NOT NULL\n\tAND "
                                             f"TRIM(EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]}) NOT "
                                             f"IN {known_carrier_list_str})")

        # Additional Lists
        only_segment_types = self.__create_sql_list(self.keep_segment_types)
        source_code_removal = self.__create_sql_list(self.remove_source_codes)
        number_string = "('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"

        return_string = f"""WITH INCLUDE_TABLE as 
(select distinct {self.database_dict['CARRIER CODE']['NEDB']}
from {self.database_dict['TERADATA TABLES']['NEDB']}
where 1=1
    and {self.database_dict['SEGMENT TYPE CODE']['NEDB']} in {only_segment_types}
    and {self.database_dict['ORIGINAL SOURCE CODE']['NEDB']} NOT IN {source_code_removal}
    and {self.database_dict['CARRIER CODE']['NEDB']} not in {general_carrier_code_removal}
    and {self.database_dict['CARRIER CODE']['NEDB']} is not null
    and (({self.database_dict['DEPENDENT BIRTH DATE']['NEDB']} <= current_date 
        and {self.database_dict['DEPENDENT BIRTH DATE']['NEDB']} >= current_date - interval '95' year) 
        OR 
        (trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}) <> ''
        and {self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']} is not null
        and left(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),1) <> '9'
        and left(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '666'
        and left(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '000'
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),4,2) <> '00'
        and right(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),4) <> '0000'
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),1,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),2,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),3,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),4,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),5,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),6,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),7,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),8,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),9,1) in {number_string}
        and length(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']})) = 9))
    and (({self.database_dict['INSURED BIRTH DATE']['NEDB']} <= current_date and {self.database_dict['INSURED BIRTH DATE']['NEDB']} >= current_date - interval '95' year) 
        OR 
        (trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}) <> ''
        and {self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']} is not null
        and left(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),1) <> '9'
        and left(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '666'
        and left(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '000'
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),4,2) <>'00'
        and right(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),4) <> '0000'
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),1,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),2,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),3,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),4,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),5,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),6,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),7,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),8,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),9,1) in {number_string}
        and length(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']})) = 9))),

EXCLUDE_TABLE as
(select distinct {self.database_dict['CARRIER CODE']['NEDB']}
from {self.database_dict['TERADATA TABLES']['NEDB']}
where {self.database_dict['SEGMENT TYPE CODE']['NEDB']} not in {only_segment_types}
    and {self.database_dict['CARRIER CODE']['NEDB']} not in {general_carrier_code_removal}
    and {self.database_dict['CARRIER CODE']['NEDB']} is not null
    and {self.database_dict['ORIGINAL SOURCE CODE']['NEDB']} NOT IN {source_code_removal}
    and (({self.database_dict['DEPENDENT BIRTH DATE']['NEDB']} <= current_date 
        and {self.database_dict['DEPENDENT BIRTH DATE']['NEDB']} >= current_date - interval '95' year) 
        OR 
        (trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}) <> ''
        and {self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']} is not null
        and left(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),1) <> '9'
        and left(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '666'
        and left(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '000'
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),4,2) <> '00'
        and right(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),4) <> '0000'
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),1,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),2,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),3,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),4,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),5,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),6,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),7,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),8,1) in {number_string}
        and substr(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}),9,1) in {number_string}
        and length(trim({self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']})) = 9))
    and (({self.database_dict['INSURED BIRTH DATE']['NEDB']} <= current_date 
        and {self.database_dict['INSURED BIRTH DATE']['NEDB']} >= current_date - interval '95' year) 
        OR 
        (trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}) <> ''
        and {self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']} is not null
        and left(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),1) <> '9'
        and left(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '666'
        and left(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),3) <> '000'
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),4,2) <>'00'
        and right(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),4) <> '0000'
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),1,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),2,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),3,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),4,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),5,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),6,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),7,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),8,1) in {number_string}
        and substr(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}),9,1) in {number_string}
        and length(trim({self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']})) = 9))),

CHECK_TABLE as
(SELECT I.{self.database_dict['CARRIER CODE']['NEDB']}, 
    CASE WHEN E.{self.database_dict['CARRIER CODE']['NEDB']} is null then 'N' else 'Y' end CHECK_IND
from INCLUDE_TABLE as I
LEFT JOIN EXCLUDE_TABLE as E 
    ON I.{self.database_dict['CARRIER CODE']['NEDB']} = E.{self.database_dict['CARRIER CODE']['NEDB']})

select {discover_carrier_cd_str}
    {emp_office_cd_str}
    {prefix_string}
    EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} as {self.sot_columns_dict['Known Carrier Code']['Column Name']},
    CASE WHEN EMP.{self.database_dict['EMPLOYER NAME']['EMP'][self.__known]} IS NULL OR TRIM(EMP.{self.database_dict['EMPLOYER NAME']['EMP'][self.__known]})='' THEN '{self.no_info_str}' 
        ELSE EMP.{self.database_dict['EMPLOYER NAME']['EMP'][self.__known]} END AS {self.sot_columns_dict['Known Employer']['Column Name']}, 
    CASE WHEN EMP.{self.database_dict['GROUP NUMBER']['EMP'][self.__known]} IS NULL OR TRIM(EMP.{self.database_dict['GROUP NUMBER']['EMP'][self.__known]})='' THEN '{self.no_info_str}' 
        ELSE EMP.{self.database_dict['GROUP NUMBER']['EMP'][self.__known]} END AS {self.sot_columns_dict['Known Group Number']['Column Name']},
    CASE WHEN EMP.{self.database_dict['INSURED STATE CODE']['EMP']} IS NULL OR TRIM(EMP.{self.database_dict['INSURED STATE CODE']['EMP']})='' THEN '{self.no_info_str}' 
        ELSE EMP.{self.database_dict['INSURED STATE CODE']['EMP']} END AS {self.sot_columns_dict['Known State Code']['Column Name']},
    SUM(case when EMP.patient_relation_to_ins_cd = '01' then 1 else 0 end) as {self.sot_columns_dict['Count of Self Policies']['Column Name']},
    SUM(case when cast(EMP.{self.database_dict['INSURED BIRTH DATE']['EMP']} as date) <= (current_date - interval '65' year) then 1 
        else 0 end) as {self.sot_columns_dict['Count of Seniors']['Column Name']},
    SUM(case when cast(EMP.{self.database_dict['INSURED BIRTH DATE']['EMP']} as date) >= (current_date - interval '18' year) then 1 
        else 0 end) as {self.sot_columns_dict['Count of Minors']['Column Name']},
    SUM(case when abs(cast(EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__known]} as date format 'YYYY-MM-DD') - 
        cast(EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__discover]} as date format 'YYYY-MM-DD')) > {self.days_for_cov_start_diff} then 1 
        else 0 end) as {self.sot_columns_dict['Count of Unrelated Start Dates']['Column Name']},
    SUM(CASE WHEN EDITDISTANCE(OREPLACE(TRIM(EMP.{self.__discover}_POLICY_NUM),' ',''), 
        OREPLACE(TRIM(EMP.{self.__known}_POLICY_NUM),' ','')) <=6 
        OR EDITDISTANCE(LEFT(RIGHT(OREPLACE(TRIM(EMP.{self.__discover}_POLICY_NUM),' ',''),11),9), 
        LEFT(RIGHT(OREPLACE(TRIM(EMP.{self.__known}_POLICY_NUM),' ',''),11),9)) <= 5 THEN 1 ELSE 0 
    END) AS {self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name']},
    {date_string}
    COUNT(*) as {self.sot_columns_dict['Count of Individual Records']['Column Name']}
from {self.database_dict['TERADATA TABLES']['EMP']} as EMP
Left JOIN 
    (Select {self.database_dict['CARRIER CODE']['FUSP']}, 
        {self.database_dict['INSURED FIRST NAME']['FUSP']}, 
        {self.database_dict['INSURED LAST NAME']['FUSP']}, 
        {self.database_dict['INSURED SOCIAL SECURITY NUMBER']['FUSP']}, 
        {self.database_dict['INSURED BIRTH DATE']['FUSP']}, 
        {self.database_dict['DEPENDENT FIRST NAME']['FUSP']}, 
        {self.database_dict['DEPENDENT LAST NAME']['FUSP']}, 
        {self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['FUSP']}, 
        {self.database_dict['DEPENDENT BIRTH DATE']['FUSP']}, 
        {self.database_dict['POLICY START DATE']['FUSP']}
    from {self.database_dict['TERADATA TABLES']['FUSP']}
    WHERE {self.__fusp_medicare_filter()}
    ) as F ON ((EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} = F.{self.database_dict['CARRIER CODE']['FUSP']} 
                AND EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__discover]} = F.{self.database_dict['POLICY START DATE']['FUSP']}) 
            OR (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} = F.{self.database_dict['CARRIER CODE']['FUSP']} 
                AND EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__known]} = F.{self.database_dict['POLICY START DATE']['FUSP']})) 
        AND F.{self.database_dict['INSURED FIRST NAME']['FUSP']} = EMP.{self.database_dict['INSURED FIRST NAME']['EMP']}
        AND F.{self.database_dict['INSURED LAST NAME']['FUSP']} = EMP.INSURED_LAST_NM
        AND F.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['FUSP']} = EMP.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['EMP']}
        AND F.{self.database_dict['INSURED BIRTH DATE']['FUSP']} = EMP.{self.database_dict['INSURED BIRTH DATE']['EMP']}
        AND F.{self.database_dict['DEPENDENT FIRST NAME']['FUSP']} = EMP.{self.database_dict['DEPENDENT FIRST NAME']['EMP']}
        AND F.{self.database_dict['DEPENDENT LAST NAME']['FUSP']} = EMP.{self.database_dict['DEPENDENT LAST NAME']['EMP']}
        AND F.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['FUSP']} = EMP.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['EMP']}
        AND F.{self.database_dict['DEPENDENT BIRTH DATE']['FUSP']} = EMP.{self.database_dict['DEPENDENT BIRTH DATE']['EMP']}
JOIN CHECK_TABLE as C_MED ON EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} = C_MED.{self.database_dict['CARRIER CODE']['NEDB']}
JOIN CHECK_TABLE as C_RX ON EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} = C_RX.{self.database_dict['CARRIER CODE']['NEDB']}
--- JOIN TO {self.database_dict['TERADATA TABLES']['NEDB']} WHEN CHECK_IND = 'Y' AND KEEP DATA WHERE {self.database_dict['SEGMENT TYPE CODE']['NEDB']} in {only_segment_types} BASED ON EMP DATA
Left JOIN 
    (Select NEDB.{self.database_dict['CARRIER CODE']['NEDB']}, 
        {self.database_dict['GROUP NUMBER']['NEDB']}, 
        {self.database_dict['INSURED FIRST NAME']['NEDB']}, 
        {self.database_dict['INSURED LAST NAME']['NEDB']} , 
        {self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']}, 
        {self.database_dict['INSURED BIRTH DATE']['NEDB']}, 
        {self.database_dict['DEPENDENT FIRST NAME']['NEDB']}, 
        {self.database_dict['DEPENDENT LAST NAME']['NEDB']}, 
        {self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']}, 
        {self.database_dict['DEPENDENT BIRTH DATE']['NEDB']}, 
        {self.database_dict['POLICY START DATE']['NEDB'][self.__discover]}, 
        {self.database_dict['POLICY START DATE']['NEDB'][self.__known]}
    from {self.database_dict['TERADATA TABLES']['NEDB']} as NEDB
    JOIN CHECK_TABLE as CH 
        ON CH.{self.database_dict['CARRIER CODE']['NEDB']} = NEDB.{self.database_dict['CARRIER CODE']['NEDB']} 
            and CH.CHECK_IND = 'Y'
    WHERE {self.database_dict['SEGMENT TYPE CODE']['NEDB']} not in {only_segment_types}
    ) as N ON 
        ((EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__discover]} = N.{self.database_dict['CARRIER CODE']['NEDB']} 
                AND EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__discover]} = N.{self.database_dict['POLICY START DATE']['NEDB'][self.__discover]} 
                AND EMP.{self.database_dict['GROUP NUMBER']['EMP'][self.__discover]} = N.{self.database_dict['GROUP NUMBER']['NEDB']}) 
            OR (EMP.{self.database_dict['CARRIER CODE']['EMP'][self.__known]} = N.{self.database_dict['CARRIER CODE']['NEDB']} 
                AND EMP.{self.database_dict['POLICY START DATE']['EMP'][self.__known]} = N.{self.database_dict['POLICY START DATE']['NEDB'][self.__known]} 
                AND EMP.{self.database_dict['GROUP NUMBER']['EMP'][self.__known]} = N.{self.database_dict['GROUP NUMBER']['NEDB']})) 
        AND N.{self.database_dict['INSURED FIRST NAME']['NEDB']} = EMP.{self.database_dict['INSURED FIRST NAME']['EMP']}
        AND N.{self.database_dict['INSURED LAST NAME']['NEDB']} = EMP.{self.database_dict['INSURED LAST NAME']['EMP']}
        AND N.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']} = EMP.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['EMP']}
        AND N.{self.database_dict['INSURED BIRTH DATE']['NEDB']} = EMP.{self.database_dict['INSURED BIRTH DATE']['EMP']}
        AND N.{self.database_dict['DEPENDENT FIRST NAME']['NEDB']} = EMP.{self.database_dict['DEPENDENT FIRST NAME']['EMP']}
        AND N.{self.database_dict['DEPENDENT LAST NAME']['NEDB']} = EMP.{self.database_dict['DEPENDENT LAST NAME']['EMP']}
        AND N.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']} = EMP.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['EMP']}
        AND N.{self.database_dict['DEPENDENT BIRTH DATE']['NEDB']} = EMP.{self.database_dict['DEPENDENT BIRTH DATE']['EMP']}
where 1=1
    and {self.database_dict['POLICY START DATE']['EMP'][self.__known]} is not null 
    and {self.database_dict['POLICY START DATE']['EMP'][self.__discover]} is not null
    {filter_known_carrier_code_str}
    {filter_discover_carrier_code_str}
    {known_equals_discover_str}
    AND (F.{self.database_dict['CARRIER CODE']['FUSP']} is null 
        AND F.{self.database_dict['POLICY START DATE']['FUSP']} is null 
        AND F.{self.database_dict['INSURED FIRST NAME']['FUSP']} is null 
        AND F.{self.database_dict['INSURED LAST NAME']['FUSP']} is null 
        AND F.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['FUSP']} is null 
        AND F.{self.database_dict['INSURED BIRTH DATE']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT FIRST NAME']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT LAST NAME']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['FUSP']} is null 
        AND F.{self.database_dict['DEPENDENT BIRTH DATE']['FUSP']} is null) -- Join Conditions Excluded
    AND (N.{self.database_dict['CARRIER CODE']['NEDB']} is null 
        AND N.{self.database_dict['GROUP NUMBER']['NEDB']} is null 
        AND N.{self.database_dict['POLICY START DATE']['NEDB'][self.__discover]} is null 
        AND N.{self.database_dict['POLICY START DATE']['NEDB'][self.__known]} is null 
        AND N.{self.database_dict['INSURED FIRST NAME']['NEDB']} is null 
        AND N.{self.database_dict['INSURED LAST NAME']['NEDB']} is null 
        AND N.{self.database_dict['INSURED SOCIAL SECURITY NUMBER']['NEDB']} is null 
        AND N.{self.database_dict['INSURED BIRTH DATE']['NEDB']} is null 
        AND N.{self.database_dict['DEPENDENT FIRST NAME']['NEDB']} is null 
        AND N.{self.database_dict['DEPENDENT LAST NAME']['NEDB']} is null 
        AND N.{self.database_dict['DEPENDENT SOCIAL SECURITY NUMBER']['NEDB']} is null 
        AND N.{self.database_dict['DEPENDENT BIRTH DATE']['NEDB']} is null)
GROUP BY 1,2,3,4,5{prefix_group_by_num}{office_group_by_num}
"""
        # print(f'\n\n\n{return_string}\n\n\n')
        return return_string

    def sql_for_gap_data(self):
        """Create the SQL to collect the potential medicaid gap counts for each combination"""
        general_carrier_code_removal = self.__create_sql_list(self.remove_carrier_codes)
        database_union_list = [self.database_dict['CARRIER CODE']['EMP'][self.__known],
                               self.database_dict['EMPLOYER NAME']['EMP'][self.__known],
                               self.database_dict['GROUP NUMBER']['EMP'][self.__known],
                               self.database_dict['INSURED STATE CODE']['EMP']]
        columns_union_list = [self.sot_columns_dict['Known Carrier Code']['Column Name'],
                              self.sot_columns_dict['Known Employer']['Column Name'],
                              self.sot_columns_dict['Known Group Number']['Column Name'],
                              self.sot_columns_dict['Known State Code']['Column Name']]
        combos_list = []
        for r in range(len(database_union_list), 0, -1):
            combinations_r = combinations(database_union_list, r)
            combos_list.extend([list(tup) for tup in combinations_r])

        union_string = ''

        for combo_item in combos_list:
            if union_string != '':
                union_string += f'UNION\nSELECT '
            else:
                union_string = 'SELECT '

            for database_list_item, columns_list_item in zip(database_union_list, columns_union_list):
                if database_list_item in combo_item:
                    union_string += f'{database_list_item} as {columns_list_item}, '
                else:
                    union_string += f"'{self.empty_str}' as {columns_list_item}, "

            union_string += (f"sum({self.sot_columns_dict['Potential Medicare Population Gap']['Column Name']}) as "
                             f"{self.sot_columns_dict['Potential Medicare Population Gap']['Column Name']}\nFROM "
                             f"GENERAL_POTENTIAL_GAP\n\nGroup By 1,2,3,4\n")

        return_string = f"""
WITH GENERAL_POTENTIAL_GAP as
(SELECT {self.database_dict['CARRIER CODE']['EMP'][self.__known]} as {self.sot_columns_dict['Known Carrier Code']['Column Name']}, 
    CASE WHEN {self.database_dict['EMPLOYER NAME']['EMP'][self.__known]} IS NULL OR TRIM({self.database_dict['EMPLOYER NAME']['EMP'][self.__known]})='' THEN '{self.no_info_str}' 
        ELSE TRIM({self.database_dict['EMPLOYER NAME']['EMP'][self.__known]}) END AS {self.sot_columns_dict['Known Employer']['Column Name']}, 
    CASE WHEN {self.database_dict['GROUP NUMBER']['EMP'][self.__known]} IS NULL OR TRIM({self.database_dict['GROUP NUMBER']['EMP'][self.__known]})='' THEN '{self.no_info_str}' 
        ELSE TRIM({self.database_dict['GROUP NUMBER']['EMP'][self.__known]}) END AS {self.sot_columns_dict['Known Group Number']['Column Name']},
    CASE WHEN {self.database_dict['INSURED STATE CODE']['EMP']} IS NULL OR TRIM({self.database_dict['INSURED STATE CODE']['EMP']})='' THEN '{self.no_info_str}' 
        ELSE TRIM({self.database_dict['INSURED STATE CODE']['EMP']}) END AS {self.sot_columns_dict['Known State Code']['Column Name']},
    COUNT(*) AS {self.sot_columns_dict['Potential Medicare Population Gap']['Column Name']}
FROM {self.database_dict['TERADATA TABLES']['EMP']}
WHERE 1=1
    and ({self.database_dict['CARRIER CODE']['EMP'][self.__discover]} IS NULL 
        OR TRIM({self.database_dict['CARRIER CODE']['EMP'][self.__discover]}) = '')
    AND ({self.database_dict['CARRIER CODE']['EMP'][self.__known]} IS NOT NULL 
        AND TRIM({self.database_dict['CARRIER CODE']['EMP'][self.__known]}) not in {general_carrier_code_removal})
    and (trim({self.database_dict['DEPENDENT MEDICAID NUMBER']['EMP']}) <> '' 
        and {self.database_dict['DEPENDENT MEDICAID NUMBER']['EMP']} is not null)
GROUP BY 1,2,3,4
)

{union_string}"""
        return return_string

    # def __update_sot_sql_table(self, df: pd.DataFrame, database_name: str, table_name: str, dsn: str = 'EDWPROD',
    #                            archive_table_name: str = f'{table_name}_ARCH'):
    #     database_name = database_name.upper()
    #     table_name = table_name.upper()
    #     archive_table_name = archive_table_name.upper()
    #
    #     # Check if the Table exists
    #     table_available = check_if_table_exists(database_name=database, table_name=table_name, dsn=dsn)
    #     if table_available:
    #         # Check if the Archive Table exists
    #         table_available = check_if_table_exists(database_name=database, table_name=archive_table_name, dsn=dsn)
    #         if not table_available:
    #             # Create Archive
    #
    #         # Move old data to Archive
    #         exit() #################################################################### need to do something here!!!
    #
    #         # Delete Old Table
    #         delete_sql_table(database_name=database_name, table_name=table_name, dsn=dsn)
    #
    #     # Create Table
    #     set_string = self.__create_set_string()
    #     set_list = list()
    #     for key, value in self.sot_columns_dict.items():
    #         if value[set_string]['Keep']:
    #             set_list.append((value[set_string]['Order'], value['Column Name'], value['SQL Datatype']))
    #
    #     set_list.sort(key=lambda x: x[0])
    #
    #     create_table_sql = f"""create set table {database_name}.{table_name}, FALLBACK,
    #         NO BEFORE JOURNAL,
    #         NO AFTER JOURNAL,
    #         CHECKSUM = DEFAULT,
    #         DEFAULT MERGEBLOCKRATIO,
    #         MAP = TD_MAP1
    #         (ROW_ID BIGINT GENERATED ALWAYS AS IDENTITY
    #             (START WITH 1
    #             INCREMENT BY 1
    #             MINVALUE 0
    #             MAXVALUE 999999999999999999
    #             NO CYCLE),"""
    #
    #     for item in set_list:
    #         if item != set_list[-1]:
    #             create_table_sql += f"""\n\t{item[1]} {item[2]},"""
    #         else:
    #             create_table_sql += f"""\n\t{item[1]} {item[2]})
    #     PRIMARY INDEX ( ROW_ID )"""
    #
    #     print(f'Set Columns:\n{set_columns_list}\n\n{create_table_sql}\n\n')
    #
    #     execute_sql_code(sql=create_table_sql, dsn=dsn)
    #
    #     # Insert Data into Table
    #     insert_df_into_sql_table(df=df, database_name=database_name, table_name=table_name, dsn=dsn)
    #     print(f'{database_name}.{table_name} is now available in Teradata with the new data!')

    def __create_sql_table(self, df: pd.DataFrame, database_name: str, table_name: str, set_string: str,
                           dsn: str = 'EDWPROD'):
        start_time = datetime.datetime.now()
        database_name = database_name.upper()
        table_name = table_name.upper()

        # Check if the Table exists
        table_available = check_if_table_exists(database_name=database_name, table_name=table_name, dsn=dsn)
        if table_available:
            raise FileExistsError("Table Already exists, please delete it if you'd like to create a "
                                  "new table for updates...")

        # Create Table
        set_list = list()
        for key, value in self.sot_columns_dict.items():
            if value[set_string]['Keep']:
                set_list.append((value[set_string]['Order'], value['Column Name'], value['SQL Datatype']))

        set_list.sort(key=lambda x: x[0])

        create_table_sql = f"""create set table {database_name}.{table_name}, FALLBACK,
            NO BEFORE JOURNAL,
            NO AFTER JOURNAL,
            CHECKSUM = DEFAULT,
            DEFAULT MERGEBLOCKRATIO,
            MAP = TD_MAP1
            ("""

        for item in set_list:
            if item != set_list[-1]:
                create_table_sql += f"\n\t{item[1]} {item[2]},"
            else:
                create_table_sql += f"\n\t{item[1]} {item[2]})\nPRIMARY INDEX ( {set_list[0][1]} )"

        if self.sot_columns_dict['Row Number']['Column Name'] == set_list[0][1]:
            create_table_sql += f"\n, SECONDARY INDEX ( {set_list[1][1]} )"

        print(f'Set Columns:\n{set_list}\n\n{create_table_sql}\n\n')

        execute_sql_code(sql=create_table_sql, dsn=dsn)

        # Insert Data into Table
        insert_df_into_sql_table(df=df, database_name=database_name, table_name=table_name, dsn=dsn)
        print(f'{database_name}.{table_name} is now available in Teradata with the new data!'
              f'Table Creation and Insert Time: {datetime.datetime.now() - start_time}')

    def __get_combo_numbers(self, df: pd.DataFrame, database_name: str = 'DL_Marshall',
                            table_name: str = 'SOT_KNOWLEDGE_XWALK', send_to_table=False):
        """This function is to find, or create, a COMBO_ID for the Med and RX info that is placed on the SOT Table."""
        # Create a list of the needed columns and determine if there is already data available
        keep_columns = ([self.sot_columns_dict['Recommended Carrier Code']['Column Name']] +
                        self.initial_group_by_columns)
        table_exists = check_if_table_exists(database_name=database_name, table_name=table_name)

        # Get the data from the provided dataframe
        potential_combos_df = df[keep_columns]
        potential_combos_df.drop_duplicates()

        if table_exists:
            # Collect the existing data
            sql_str = f"Select * from {database_name}.{table_name}"
            combo_df = read_sql_to_df(sql=sql_str)

            # Find missing data
            potential_combos_df = pd.merge(potential_combos_df, combo_df[keep_columns], on=keep_columns, how='left',
                                           indicator=True)
            potential_combos_df = potential_combos_df.loc[potential_combos_df['_merge'] == 'left_only']
            potential_combos_df.drop(columns=['_merge'], inplace=True)

        else:
            combo_df = pd.DataFrame(columns=[self.sot_columns_dict['Combo Number']['Column Name']] + keep_columns)

        # Check if there are new combs
        missing_combo_num = potential_combos_df.shape[0]
        if missing_combo_num > 0:
            # Determine starting number for new data then the corresponding list of values
            next_value = 0
            if table_exists:
                next_value = combo_df[self.sot_columns_dict['Combo Number']['Column Name']].max()
            next_value += 1

            next_numbers = pd.Series(range(next_value, next_value + missing_combo_num))
            potential_combos_df.insert(loc=0, column=self.sot_columns_dict['Combo Number']['Column Name'],
                                       value=next_numbers)
            print(f'{potential_combos_df.columns}\n\n{potential_combos_df}')

        if send_to_table:
            if not table_exists:
                # Create table
                set_string = 'Reference Table'
                self.__create_sql_table(df=potential_combos_df, database_name=database_name, table_name=table_name,
                                        set_string=set_string)
            else:
                # Upload new items
                insert_df_into_sql_table(df=potential_combos_df, database_name=database_name, table_name=table_name)

        # Return full table
        combo_df = pd.merge(combo_df, potential_combos_df,
                            on=[self.sot_columns_dict['Combo Number']['Column Name']] + keep_columns, how='outer')
        return combo_df

    def __clean_prefixes_and_group_data_v2(self, df: pd.DataFrame):
        def gather_known_bcbs_prefixes():
            sql = (f"select distinct {self.database_dict['PREFIX']['PREF']}\n"
                   f"from {self.database_dict['TERADATA TABLES']['PREF']}")
            return_df = read_sql_to_df(sql=sql)
            return_list = return_df.values.tolist()
            return return_list

        def find_prefix_root(row, root_length: int):
            string = str(row['NEW_POLICY_PREFIX'])
            length = len(string)

            if length >= root_length:
                return_string = string[:root_length]
            else:
                return_string = string

            return return_string

        def valid_prefix(row, replace_string: str = ''):
            # Check if its being used in the check length function, if so, the 'row' will actually be the string
            if replace_string != '':
                return_string = replace_string
            else:
                return_string = str(row[self.sot_columns_dict['Recommended Prefix']['Column Name']])

            blue_cross_check = self.__bcbs_carrier_cd_check(row)

            if self.blue_prefix_only and not blue_cross_check:
                return_string = ''

            if self.__max_prefix_length > self.__max_bcbs_prefix_length and len(
                    return_string) > self.__max_bcbs_prefix_length:
                if blue_cross_check:
                    return_string = return_string[:self.__max_bcbs_prefix_length]

            # Check if a string has any bad characters, if so, return blank
            if return_string != '':
                carrier_cd = row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']]
                if not (blue_cross_check and return_string in known_bcbs_prefixes_list):
                    if not re.match(r'^[0-9a-zA-Z]*$', return_string):
                        return_string = ''
                    # Check if a string is all numbers
                    elif re.match(r'^[0-9]*$', return_string):
                        return_string = ''
                    # Check if a string is one or more letters and then two or more numbers
                    elif re.match(r'^[a-zA-Z]+[0-9]+$', return_string):  # Originally r'^[a-zA-Z]+[0-9]{2,}$'
                        # Check if the string should be cleaned or cut
                        number = re.search(r'[0-9]+$', return_string).start()  # Originally r'^[a-zA-Z]+[0-9]{2,}$'
                        return_string = return_string[0:number]
                        if blue_cross_check and len(return_string) < self.__min_bcbs_prefix_length:
                            if re.match(r'.*F$', carrier_cd) and len(carrier_cd) == 5:
                                return_string = return_string[0]
                            else:
                                return_string = ''
                        elif len(return_string) < self.__min_prefix_length:
                            return_string = ''
                    elif len(return_string) < self.__min_prefix_length:
                        if re.match(r'.*F$', carrier_cd) and len(carrier_cd) == 5 and blue_cross_check:
                            return_string = return_string[0]
                        else:
                            return_string = ''

            return return_string

        def check_prefix_counts(row, root_length: int):
            """Check that at least 1 root is either greater than or equal to the min prefixes
            OR that it is 10% of one of the combos. If it is not, return blank, otherwise return the prefix."""
            initial_string = str(row['NEW_POLICY_PREFIX'])

            if initial_string != '' and len(initial_string) >= root_length:
                check_bln = False
                for x in range(1, total_combos + 1):
                    if row[f'COMBO_{x}_COUNT_FOR_ROOT'] >= self.num_emp_on_discover_prefix_min \
                            and row[f'COMBO_{x}_RATIO_FOR_ROOT'] >= 0.05:
                        check_bln = True
                        break

                if check_bln:
                    return_string = initial_string
                elif self.__bcbs_carrier_cd_check(row):
                    carrier_cd = row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']]
                    if root_length <= 3 and not re.match(r'.*F$', carrier_cd):
                        return_string = ''
                    else:
                        return_string = initial_string
                elif root_length > 1:
                    return_string = row['PREFIX_ROOT_PREVIOUS']
                else:
                    return_string = ''

                if return_string != '':
                    return_string = valid_prefix(row=row, replace_string=return_string)

            else:
                return_string = initial_string

            return return_string

        def clean_by_length(row):
            if row[f'MAX_LENGTH_FOR_ROOT'] != row[f'PREFIX_LENGTH']:
                return_string = ''
            else:
                return_string = row['NEW_POLICY_PREFIX']
            return return_string

        def check_top_prefixes(row, ratio):
            return_string = row[self.sot_columns_dict['Top Prefix for Carrier']['Column Name']]
            if row['DISCOVER_OCCURRENCE'] > 1:
                if row['OCCURRENCE_RATIO'] < ratio:
                    return_string = ''
            return return_string

        def check_for_prefixes(df_inner):
            if 'NEW_POLICY_PREFIX' in df.columns:
                keep_col = self.primary_discover_columns + ['NEW_POLICY_PREFIX']
            else:
                keep_col = self.primary_discover_columns + [self.sot_columns_dict['Recommended Prefix']['Column Name']]
            check_df = df_inner[keep_col].copy()
            check_df.drop_duplicates(inplace=True)
            check_df = check_df.loc[(check_df[keep_col[1]] != '')]
            carrier_cds = check_df[keep_col[0]].values.tolist()
            df_inner = df_inner[df_inner[keep_col[0]].isin(carrier_cds)]
            return df_inner

        def bcbs_federal_carrier_cd_check(row):
            carrier_code = row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']]
            if len(carrier_code) == 5 or len(carrier_code) == 4:
                if self.__bcbs_carrier_cd_check(row):
                    prefix = row[self.sot_columns_dict['Recommended Prefix']['Column Name']]
                    if (re.match(r'^R[0-9]{2}.*', prefix) or
                            (re.match(r'.*F$', carrier_code) and (re.match(r'^[0-9].*', prefix)
                                                                  or prefix == ''))):
                        if not re.match(r'.*F$', carrier_code) and len(carrier_code) == 4:
                            carrier_code += 'F'
                    elif re.match(r'.*F$', carrier_code) and len(carrier_code) == 5:
                        carrier_code = carrier_code[:4]

                    if (carrier_code != row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']] and
                            re.match(r'^[^R].*[0-9]{2,}$', prefix)):
                        print(f"Old Carrier Code:{row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']]}"
                              f" | New Carrier Code: {carrier_code} | Current Prefix: {prefix}")
            return carrier_code

        print('Starting Prefix Cleaning...')
        df[self.sot_columns_dict['Recommended Carrier Code']['Column Name']] = df.apply(bcbs_federal_carrier_cd_check,
                                                                                        axis=1)
        known_bcbs_prefixes_list = gather_known_bcbs_prefixes()
        df[self.sot_columns_dict['Recommended Prefix']['Column Name']] = df.apply(valid_prefix, axis=1)
        grouped_df = df.groupby(self.all_group_by_columns, as_index=False, dropna=False).agg(self.agg_dict)
        print(f'{grouped_df.shape}')

        # Prep the Dataframe for cleaning prefixes
        limited_df = check_for_prefixes(grouped_df[self.all_group_by_columns + [
            self.sot_columns_dict['Count of Individual Records']['Column Name']]])

        limited_df['DISCOVER_SUM'] = \
            limited_df.groupby(self.primary_discover_columns)[
                self.sot_columns_dict['Count of Individual Records']['Column Name']].transform('sum')

        # Create the New Prefix column
        limited_df['NEW_POLICY_PREFIX'] = limited_df[self.sot_columns_dict['Recommended Prefix']['Column Name']]

        # The idea for this is to find prefixes that are in the top 10 of a combo, preferably with 10+% of the
        # population of a combo. If it is not in that 10% then it should be stripped down and checked again.
        # Minimum prefix count still applies. Also, like in the first version, if the root is the same as another root
        # within the same {self.__discover} Carrier then it should be added back onto (or maybe just outright removed?).
        # self.group_by_combos_list = generate_combinations(self.initial_group_by_columns)
        total_combos = len(self.group_by_combos_list)

        for i, combo_list in zip(range(1, total_combos + 1), self.group_by_combos_list):
            group_by_columns = self.primary_discover_columns[:] + combo_list
            limited_df[f'COMBO_{i}_COUNT'] = \
                limited_df.groupby(group_by_columns)[
                    self.sot_columns_dict['Count of Individual Records']['Column Name']].transform('sum')

        limited_df.drop(
            limited_df[limited_df[self.sot_columns_dict['Recommended Prefix']['Column Name']] == ''].index,
            inplace=True)

        orig_max_prefix_len = limited_df[self.sot_columns_dict['Recommended Prefix']['Column Name']].str.len().max()

        for n in range(1, orig_max_prefix_len + 1):
            limited_df['PREFIX_ROOT_CURRENT'] = limited_df.apply(find_prefix_root, root_length=n, axis=1)
            for i, combo_list in zip(range(1, total_combos + 1), self.group_by_combos_list):
                group_by_columns = self.primary_discover_columns[:] + ['PREFIX_ROOT_CURRENT'] + combo_list
                limited_df[f'COMBO_{i}_COUNT_FOR_ROOT'] = limited_df.groupby(group_by_columns
                                                                             )[
                    self.sot_columns_dict['Count of Individual Records']['Column Name']].transform(
                    'sum')
                limited_df[f'COMBO_{i}_RATIO_FOR_ROOT'] = \
                    round(limited_df[f'COMBO_{i}_COUNT_FOR_ROOT'] / limited_df[f'COMBO_{i}_COUNT'],
                          self.use_decimal_precision)
            limited_df['NEW_POLICY_PREFIX'] = limited_df.apply(check_prefix_counts, root_length=n, axis=1)
            limited_df['PREFIX_ROOT_PREVIOUS'] = limited_df['PREFIX_ROOT_CURRENT']
            limited_df.drop(limited_df[limited_df['NEW_POLICY_PREFIX'] == ''].index, inplace=True)
        print(f"Done with Prefix Cleaning Loop\n")

        # Prep for final dataframe
        r_keep_columns = self.all_discover_columns + ['NEW_POLICY_PREFIX']
        limited_df = limited_df.groupby(
            r_keep_columns + ['DISCOVER_SUM'], as_index=False,
            dropna=False
        ).agg({self.sot_columns_dict['Count of Individual Records']['Column Name']: 'sum'})

        # Keep the longest version of the prefix
        temp_df = limited_df.groupby(self.all_discover_columns, as_index=False, dropna=False
                                     )['NEW_POLICY_PREFIX'].agg(lambda x: max(x, key=len))
        print(f'Shape of Paired Down DF: {limited_df.shape}\n'
              f'Blanks in dataframe: {len(limited_df[limited_df["NEW_POLICY_PREFIX"] == ""])}')
        limited_df = limited_df[
            self.all_discover_columns + [self.sot_columns_dict['Count of Individual Records']['Column Name'],
                                         'DISCOVER_SUM']]
        limited_df = limited_df.merge(
            right=temp_df[self.all_discover_columns + ['NEW_POLICY_PREFIX']],
            on=self.all_discover_columns, how='left')
        del temp_df

        # Add something here to make longer prefixes where they share a base?
        # Or remove them since they don't have something significant enough?
        # --- Remove them as they aren't significant enough - Doesn't need to go to the max, one under the max is fine
        new_max_prefix_len = limited_df['NEW_POLICY_PREFIX'].str.len().max()
        new_min_prefix_len = limited_df['NEW_POLICY_PREFIX'].str.len().min()

        if new_max_prefix_len != new_min_prefix_len:
            limited_df[f'PREFIX_LENGTH'] = limited_df['NEW_POLICY_PREFIX'].str.len()
            for n in range(new_min_prefix_len, new_max_prefix_len):
                limited_df['PREFIX_ROOT_CURRENT'] = limited_df.apply(find_prefix_root, root_length=n, axis=1)
                limited_df[f'MAX_LENGTH_FOR_ROOT'] = limited_df.groupby(['PREFIX_ROOT_CURRENT']
                                                                        )[f'PREFIX_LENGTH'].transform('max')
                limited_df['NEW_POLICY_PREFIX'] = limited_df.apply(clean_by_length, axis=1)
                limited_df.drop(limited_df[limited_df['NEW_POLICY_PREFIX'] == ''].index,
                                inplace=True)

        limited_df = limited_df.groupby(
            r_keep_columns + ['DISCOVER_SUM'], as_index=False,
            dropna=False
        ).agg({self.sot_columns_dict['Count of Individual Records']['Column Name']: 'sum'})

        # Find the 'Most Popular' Prefix for each carrier
        limited_df['OCCURRENCE_SUM'] = limited_df.groupby(
            [self.sot_columns_dict['Recommended Carrier Code']['Column Name'], 'NEW_POLICY_PREFIX']
        )[self.sot_columns_dict['Count of Individual Records']['Column Name']].transform('sum')

        top_df = limited_df.loc[(limited_df['OCCURRENCE_SUM'] != 0)]

        # Drop Unneeded columns, rows, and rename prefix column
        top_df = top_df[
            self.primary_discover_columns[:] + ['NEW_POLICY_PREFIX',
                                                'OCCURRENCE_SUM',
                                                'DISCOVER_SUM']]
        limited_df = limited_df[r_keep_columns]
        top_df.drop_duplicates(inplace=True, ignore_index=True)
        top_df.rename(columns={
            'NEW_POLICY_PREFIX': self.sot_columns_dict['Top Prefix for Carrier']['Column Name']},
            inplace=True)

        top_df['OCCURRENCE_RATIO'] = round(
            top_df['OCCURRENCE_SUM'] / top_df['DISCOVER_SUM'],
            self.use_decimal_precision)
        top_df['MAX_PREFIX_RATIO'] = top_df.groupby(self.primary_discover_columns
                                                    )['OCCURRENCE_RATIO'].transform('max')
        top_df = top_df.loc[(top_df['MAX_PREFIX_RATIO'] == top_df['OCCURRENCE_RATIO'])]

        # Check if a Carrier has multiple 'top' prefixes
        top_df['DISCOVER_OCCURRENCE'] = top_df.groupby(self.primary_discover_columns)[
            self.primary_discover_columns[0]].transform('count')
        prefix_ratio = 0.2

        while any(top_df['DISCOVER_OCCURRENCE'] > 1) and prefix_ratio <= 0.51:
            top_df[self.sot_columns_dict['Top Prefix for Carrier']['Column Name']] = top_df.apply(
                check_top_prefixes, ratio=prefix_ratio, axis=1)
            top_df = top_df[top_df[self.sot_columns_dict['Top Prefix for Carrier']['Column Name']] != '']
            top_df['DISCOVER_OCCURRENCE'] = top_df.groupby(self.primary_discover_columns)[
                self.primary_discover_columns[0]].transform('count')
            prefix_ratio += 0.01

        if any(top_df['DISCOVER_OCCURRENCE'] > 1):
            print(f'{top_df.shape}\n\nERROR: Multiple Top Prefixes even though ratio is set to {prefix_ratio}!')
            exit()

        top_df = top_df[
            self.primary_discover_columns[:] + [self.sot_columns_dict['Top Prefix for Carrier']['Column Name']]]

        print(f'Blanks in dataframe: {len(limited_df[limited_df["NEW_POLICY_PREFIX"] == ""])}\n')

        # Merge the limited (prefix) dataframe with the full dataframe, dropping the old prefix column
        print(f'Shape of 1st DF: {limited_df.shape}\nShape of 2nd DF: {grouped_df.shape}\n')
        intermittent_df = grouped_df.merge(right=limited_df, on=self.all_discover_columns, how='left')
        intermittent_df.drop(columns=[self.sot_columns_dict['Recommended Prefix']['Column Name']], inplace=True)
        intermittent_df.rename(
            columns={'NEW_POLICY_PREFIX': self.sot_columns_dict['Recommended Prefix']['Column Name']},
            inplace=True)
        intermittent_df.fillna('', inplace=True)
        print(f'Shape of Combined DF: {intermittent_df.shape}')

        # Get the final dataframe by aggregating the data in the prior merged dataframe
        final_df = intermittent_df.groupby(self.all_group_by_columns, as_index=False, dropna=False).agg(self.agg_dict)
        print(f'Shape of Aggregated DF before Top:{final_df.shape}')
        final_df = final_df.merge(top_df, on=self.primary_discover_columns,
                                  how='left')
        print(f'Shape of Aggregated DF After Top:{final_df.shape}')
        final_df.fillna(f'{self.empty_str}', inplace=True)

        return final_df

    def __collect_all_data(self):
        start_time = datetime.datetime.now()

        if self.__known == self.__discover:
            raise ValueError(f'The variables known and discover must be different Coverage Types. Currently, both are '
                             f'{self.__known}.\nThe allowed list of Coverage Types is {self.allowed_coverages}.')

        if self.specify_discover_carriers:
            discover_carriers_df = self.specific_discover_carriers_df
        else:
            discover_carriers_df = read_sql_to_df(sql=self.sql_for_carriers())
        print(f'{self.__discover} Carriers:\n{discover_carriers_df}\n')

        total_merge_time = None
        total_query_time = None
        total_clean_time = None

        min_records_on_sql = 50000000
        max_index = discover_carriers_df.shape[0] - 1
        record_count = 0
        discover_carriers_list = []
        add_on_df = pd.DataFrame()
        internal_data_df = pd.DataFrame()

        for index, row in tqdm(discover_carriers_df.iterrows(), desc=f'Collecting Data', leave=False,
                               total=discover_carriers_df.shape[0]):
            carrier = row[self.sot_columns_dict['Recommended Carrier Code']['Column Name']]
            discover_carriers_list.append(carrier)

            if carrier in self.carrier_code_change_dict[self.__discover].values():
                keys = [k for k, v in self.carrier_code_change_dict[self.__discover].items() if v == carrier]
                for k in keys:
                    discover_carriers_list.append(k)

            if record_count == 0:
                record_count = row[f'TOTAL_RECORDS']
            else:
                record_count += row[f'TOTAL_RECORDS']

            if record_count >= min_records_on_sql or index == max_index:
                print(f'\nCarriers for Run: {discover_carriers_list}\n')
                sql_for_emp_data = self.sql_for_data(discover_carriers_list)

                if internal_data_df.empty:
                    start_time_query = datetime.datetime.now()
                    internal_data_df = read_sql_to_df(sql=sql_for_emp_data)
                    total_query_time = datetime.datetime.now() - start_time_query
                    print(f'Query Time: {datetime.datetime.now() - start_time_query}')
                    print(
                        f'internal_data_df Current Size: {internal_data_df.shape}')  # \n{internal_data_df.dtypes}\n')
                    internal_data_df = self.__strip_objects_clean(internal_data_df)
                    # print(f'\n{internal_data_df.dtypes}\n')

                    if self.__include_prefix:
                        start_clean_time = datetime.datetime.now()
                        internal_data_df = self.__clean_prefixes_and_group_data_v2(internal_data_df)
                        total_clean_time = datetime.datetime.now() - start_clean_time
                        print(f'Prefix Cleaning Time: {datetime.datetime.now() - start_clean_time}')
                    print(f'\nFirst Dataframe created! Current Size: {internal_data_df.shape}\n')

                else:
                    start_time_query = datetime.datetime.now()
                    add_on_df = read_sql_to_df(sql=sql_for_emp_data)
                    total_query_time += datetime.datetime.now() - start_time_query
                    print(f'Query Time: {datetime.datetime.now() - start_time_query}')
                    print(f'add_on_df Current Size: {add_on_df.shape}\n')
                    add_on_df = self.__strip_objects_clean(add_on_df)

                    if self.__include_prefix:
                        start_clean_time = datetime.datetime.now()
                        add_on_df = self.__clean_prefixes_and_group_data_v2(add_on_df)
                        total_clean_time += datetime.datetime.now() - start_clean_time
                        print(f'Prefix Cleaning Time: {datetime.datetime.now() - start_clean_time}')

                discover_carriers_list = []
                record_count = 0

                if not add_on_df.empty:
                    print(f'\nMerging Dataframes...')
                    print(f'Shape of internal: {internal_data_df.shape}\nShape of add on: {add_on_df.shape}\n')
                    start_time_merge = datetime.datetime.now()
                    internal_data_df = pd.concat([internal_data_df, add_on_df], ignore_index=True, axis=0)
                    if total_merge_time is None:
                        total_merge_time = datetime.datetime.now() - start_time_merge
                    else:
                        total_merge_time += datetime.datetime.now() - start_time_merge
                    print(f'Merge Time: {datetime.datetime.now() - start_time_merge}')
                    print(f'Dataframes merged! Current Size: {internal_data_df.shape}\n')
                if index == max_index:
                    print('\nAll Data Collected!!!\n')

        print(f'Data Collection Time: {datetime.datetime.now() - start_time}\n'
              f'Total Query Time: {total_query_time}\n'
              f'Total Prefix Cleaning Time: {total_clean_time}\n'
              f'Total Merge Time: {total_merge_time}\n')

        return internal_data_df

    def table_creation(self, sot_save_file_and_path: str = '', send_to_table: bool = False, sot_database_name: str = '',
                       sot_table_name: str = '', dsn: str = 'EDWPROD'):
        """This is to create a Source of Truth Table based on the SOT Knowledge table created for Data Gaps. The goal
        is to find the 'Minimum Maximum' information needed to discover a potential carrier code for a coverage gap
        based on data from Known carrier information (Carrier Code, Employer on Coverage Policy, and Group Number for
        Coverage Policy) along with Insured State data for a different coverage type."""

        # Functions
        def multi_col_dense_rank_v7(df: pd.DataFrame, rank_columns: list, rank_name: str = 'RANK',
                                    additional_group_by_col: list = None, remove_all_but_best: bool = False):
            def multi_dense_rank(group):
                def internal_rank(row, col_list: list):
                    if row[f'{col_list[0]}_min'] == row[f'{col_list[0]}_max']:
                        rank = row[f'{col_list[0]}_min']
                    else:
                        possible_rank_list = [*range(row[f'{col_list[0]}_min'], row[f'{col_list[0]}_max'] + 1)]
                        check_range = range(len(possible_rank_list))

                        for x in col_list[1:]:
                            for n in check_range:
                                if row[x] != n + 1:
                                    del possible_rank_list[0]
                                else:
                                    break
                            if len(possible_rank_list) == 1:
                                break

                        rank = possible_rank_list[0]

                    return rank

                rank_df = pd.DataFrame()
                for tup, columns_df in group:
                    group_by_count = columns_df.shape[0]

                    if group_by_count > 1:
                        columns_df['base'] = 'A'
                        inner_group_col = ['base']
                        rank_column_list = []
                        for col, cnt in zip(rank_columns, range(len(rank_columns))):
                            if cnt == 0:
                                columns_df[f'{rank_name}_{cnt}_min'] = columns_df.groupby(
                                    inner_group_col)[col].rank(method='min', ascending=False).astype('int')
                                columns_df[f'{rank_name}_{cnt}_max'] = columns_df.groupby(
                                    inner_group_col)[col].rank(method='max', ascending=False).astype('int')

                            else:
                                columns_df[f'{rank_name}_{cnt}'] = columns_df.groupby(
                                    inner_group_col)[col].rank(method='min', ascending=False).astype('int')

                            inner_group_col.append(col)
                            rank_column_list.append(f'{rank_name}_{cnt}')
                            current_group_count = columns_df.groupby(inner_group_col)[inner_group_col].count()
                            if not any(current_group_count > 1):
                                break

                        # Rank based on all columns
                        columns_df['Rank'] = columns_df.apply(internal_rank, col_list=rank_column_list, axis=1)

                    else:
                        columns_df['Rank'] = 1

                    if rank_df.empty:
                        rank_df = columns_df['Rank']
                    else:
                        rank_df = pd.concat([rank_df, columns_df['Rank']])

                return rank_df

            start_time = datetime.datetime.now()

            # Create list of columns to rank by IN ORDER
            if additional_group_by_col is not None:
                jigsaw_group_by_columns = additional_group_by_col + self.initial_group_by_columns[:]
            else:
                jigsaw_group_by_columns = self.initial_group_by_columns[:]

            if remove_all_but_best:
                df_copy = df[
                    jigsaw_group_by_columns + rank_columns +
                    [self.sot_columns_dict['Column Selection Concatenation']['Column Name']]].copy()
                for column_name in rank_columns:
                    df_copy[rank_name] = df_copy.groupby(jigsaw_group_by_columns)[column_name].rank(method='min',
                                                                                                    ascending=False)
                    df_copy.drop(df_copy[df_copy[rank_name] != 1].index, inplace=True)

                df_copy.drop(columns=[rank_name] + jigsaw_group_by_columns + rank_columns, inplace=True)
                df_copy.drop_duplicates(keep='first', inplace=True)
                df_copy = df_copy[self.sot_columns_dict['Column Selection Concatenation']['Column Name']].tolist()
                df = df[df[self.sot_columns_dict['Column Selection Concatenation']['Column Name']].isin(df_copy)]

            else:
                print(f'Rank by... {rank_columns}\nAvailable columns? {df.columns}\n')
                df[rank_name] = multi_dense_rank(df.groupby(jigsaw_group_by_columns)[rank_columns])

                # Ensure that the Rank is Dense
                df[rank_name] = df.groupby(jigsaw_group_by_columns)[rank_name].rank(method='dense',
                                                                                    ascending=True)

            print(f'Dense Rank Time: {datetime.datetime.now() - start_time}')

            return df

        def group_data_with_rank(df: pd.DataFrame):
            """This function, along with the inner functions, takes all the data and creates the layers for the SOT
            table, ranks them, and removes any lines that either don't meet needed standards, set in the outermost
            function variables or the user, or are not the best combinations to use for a set of data."""

            def group_data_inner(group_by_columns: list):
                def next_info(row, prefix_info: bool = False, show_indv: bool = True, show_policy_share: bool = True):
                    if prefix_info:
                        return_string = f"PERCENT ON PREFIX: {row[self.sot_columns_dict['Percent on Overall Combination plus Prefix']['Column Name']]:.{self.__display_decimal_precision}f}%"
                        if show_indv:
                            return_string += f" | NUM INDIVIDUALS ON PREFIX: {row[self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name']]:.0f}"
                        if show_policy_share:
                            return_string += f" | PERCENT POLICY SHARE ON PREFIX: {row[self.sot_columns_dict['Percent of Shared Policy Numbers on Prefix']['Column Name']]:.{self.__display_decimal_precision}f}%"
                    else:
                        return_string = f"PERCENT ON {self.__discover}: {row[self.sot_columns_dict['Percent on Overall Combination']['Column Name']]:.{self.__display_decimal_precision}f}%"
                        if show_indv:
                            return_string += f" | NUM INDIVIDUALS ON {self.__discover}: {row[self.sot_columns_dict['Total on Overall Combination']['Column Name']]:.0f} "
                        if show_policy_share:
                            return_string += f"| PERCENT {self.__discover}-{self.__known} POLICY SHARE: {row[self.sot_columns_dict['Percent of Shared Policy Numbers']['Column Name']]:.{self.__display_decimal_precision}f}%"

                        if self.__include_prefix and not (
                                row[self.sot_columns_dict['Recommended Prefix']['Column Name']] != '' and
                                row[self.sot_columns_dict['Top Prefix for Carrier']['Column Name']] != self.empty_str):
                            return_string += f" || PERCENT ON PREFIX: {row[self.sot_columns_dict['Percent on Overall Combination plus Prefix']['Column Name']]:.{self.__display_decimal_precision}f}%"
                            if show_indv:
                                return_string += f" | NUM INDIVIDUALS ON PREFIX: {row[self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name']]:.0f}"
                            if show_policy_share:
                                return_string += f" | PERCENT {self.__discover}-{self.__known} POLICY SHARE ON PREFIX: {row[self.sot_columns_dict['Percent of Shared Policy Numbers on Prefix']['Column Name']]:.{self.__display_decimal_precision}f}%"
                    return return_string

                def selection_concat(row):
                    return_string = ''
                    if self.sot_columns_dict['Known Carrier Code']['Column Name'] in group_by_columns:
                        return_string += f" | {row[self.sot_columns_dict['Known Carrier Code']['Column Name']]}"
                    if self.sot_columns_dict['Known Employer']['Column Name'] in group_by_columns:
                        return_string += f" | {row[self.sot_columns_dict['Known Employer']['Column Name']]}"
                    if self.sot_columns_dict['Known Group Number']['Column Name'] in group_by_columns:
                        return_string += f" | {row[self.sot_columns_dict['Known Group Number']['Column Name']]}"
                    if self.sot_columns_dict['Known State Code']['Column Name'] in group_by_columns:
                        return_string += f" | {row[self.sot_columns_dict['Known State Code']['Column Name']]}"
                    return return_string

                # Create a copy of the dataframe to manipulate and determine the column selection
                df_new = df.copy()
                print(f'Size of DataFrame at start of group_data_inner:{df_new.shape}')

                # Determine the column selection length and priority
                column_selection_str = ''
                priority = 3
                if self.sot_columns_dict['Known Carrier Code']['Column Name'] in group_by_columns:
                    column_selection_str += 'C'
                    priority -= 2
                if self.sot_columns_dict['Known Employer']['Column Name'] in group_by_columns:
                    column_selection_str += 'E'
                    priority -= 0
                if self.sot_columns_dict['Known Group Number']['Column Name'] in group_by_columns:
                    column_selection_str += 'G'
                    priority -= 0
                if self.sot_columns_dict['Known State Code']['Column Name'] in group_by_columns:
                    column_selection_str += 'S'
                    priority -= 1
                df_new[self.sot_columns_dict['Column Selection Letter']['Column Name']] = column_selection_str
                df_new[self.sot_columns_dict['Column Selection Length']['Column Name']] = len(column_selection_str)
                df_new[self.sot_columns_dict['Column Selection Priority']['Column Name']] = priority
                df_new[self.sot_columns_dict['Column Selection Concatenation']['Column Name']] = df_new.apply(
                    selection_concat, axis=1)

                # Determine how many people are in the group
                df_new[self.sot_columns_dict['Total on Known Combination']['Column Name']] = \
                    df.groupby(group_by_columns)[
                        self.sot_columns_dict['Count of Individual Records']['Column Name']].transform('sum')

                print(f'Size of DataFrame before Calculations & Removals:{df_new.shape}')

                # Determine how many people have the same discover carrier in the group and calculate related columns
                group_by_columns = self.primary_discover_columns[:] + group_by_columns

                df_new[self.sot_columns_dict['Total on Overall Combination']['Column Name']] = \
                    df.groupby(group_by_columns)[
                        self.sot_columns_dict['Count of Individual Records']['Column Name']].transform('sum')
                df_new = df_new.loc[(df_new[self.sot_columns_dict['Total on Overall Combination'][
                    'Column Name']] >= self.num_emp_on_discover_min)]
                df_new.dropna(inplace=True)

                df_new[self.sot_columns_dict['Count of Self Policies']['Column Name']] = df.groupby(group_by_columns)[
                    self.sot_columns_dict['Count of Self Policies']['Column Name']].transform('sum')
                df_new = df_new.loc[
                    (round(df_new[self.sot_columns_dict['Count of Self Policies']['Column Name']] / df_new[
                        self.sot_columns_dict['Total on Overall Combination']['Column Name']],
                           self.use_decimal_precision)
                     <= self.self_ratio_max)]
                df_new.dropna(inplace=True)

                df_new[self.sot_columns_dict['Count of Seniors']['Column Name']] = df.groupby(group_by_columns)[
                    self.sot_columns_dict['Count of Seniors']['Column Name']].transform('sum')
                df_new = df_new.loc[
                    (round(df_new[self.sot_columns_dict['Count of Seniors']['Column Name']] / df_new[
                        self.sot_columns_dict['Total on Overall Combination']['Column Name']],
                           self.use_decimal_precision)
                     <= self.senior_ratio_max)]
                df_new.dropna(inplace=True)

                df_new[self.sot_columns_dict['Count of Minors']['Column Name']] = df.groupby(group_by_columns)[
                    self.sot_columns_dict['Count of Minors']['Column Name']].transform('sum')
                df_new = df_new.loc[
                    (round(df_new[self.sot_columns_dict['Count of Minors']['Column Name']] / df_new[
                        self.sot_columns_dict['Total on Overall Combination']['Column Name']],
                           self.use_decimal_precision)
                     <= self.minor_ratio_max)]
                df_new.dropna(inplace=True)

                df_new[self.sot_columns_dict['Count of Unrelated Start Dates']['Column Name']] = \
                    df.groupby(group_by_columns)[
                        self.sot_columns_dict['Count of Unrelated Start Dates']['Column Name']].transform('sum')
                df_new = df_new.loc[
                    (round(df_new[self.sot_columns_dict['Count of Unrelated Start Dates']['Column Name']] / df_new[
                        self.sot_columns_dict['Total on Overall Combination']['Column Name']],
                           self.use_decimal_precision)
                     <= self.start_diff_ratio_max)]
                df_new.dropna(inplace=True)

                df_new[self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name']] = df.groupby(
                    group_by_columns)[self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name']].transform(
                    'sum')

                if self.__include_base_dates:
                    df_new[self.sot_columns_dict['Minimum Known Start Date']['Column Name']] = \
                        df_new.groupby(group_by_columns)['MIN_START_DT'].transform('min')
                    df_new[self.sot_columns_dict['Maximum Known Start Date']['Column Name']] = \
                        df_new.groupby(group_by_columns)['MAX_START_DT'].transform('max')

                # Determine how many people have the same discover cd and prefix in the group and
                # calculate related columns ####################### Add In Carrier Code
                if self.__include_prefix:
                    group_by_columns = [self.sot_columns_dict['Recommended Prefix']['Column Name']] + group_by_columns

                    df_new[self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name']] = \
                        df.groupby(group_by_columns)[
                            self.sot_columns_dict['Count of Individual Records']['Column Name']].transform('sum')
                    df_new = df_new.loc[
                        ((df_new[self.sot_columns_dict['Total on Overall Combination plus Prefix'][
                            'Column Name']] >= self.num_emp_on_discover_prefix_min) |
                         (df_new[self.sot_columns_dict['Recommended Prefix']['Column Name']] == ''))]
                    df_new.dropna(inplace=True)

                    df_new[self.sot_columns_dict['Count of Shared Policy Numbers on Prefix']['Column Name']] = \
                        df.groupby(group_by_columns)[
                            self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name']].transform('sum')

                    if self.__include_prefix_dates and self.__include_prefix:
                        df_new[self.sot_columns_dict['Minimum Prefix Start Date']['Column Name']] = \
                            df_new.groupby(group_by_columns)['MIN_START_DT'].transform(
                                'min')
                        df_new[self.sot_columns_dict['Maximum Prefix Start Date']['Column Name']] = \
                            df_new.groupby(group_by_columns)['MAX_START_DT'].transform(
                                'max')

                # Calculate Percent Columns
                df_new[self.sot_columns_dict['Percent on Overall Combination']['Column Name']] = round(
                    100 * df_new[self.sot_columns_dict['Total on Overall Combination']['Column Name']] / df_new[
                        self.sot_columns_dict['Total on Known Combination']['Column Name']],
                    self.use_decimal_precision)
                df_new[self.sot_columns_dict['Percent of Shared Policy Numbers']['Column Name']] = \
                    round(
                        100 * df_new[self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name']] / df_new[
                            self.sot_columns_dict['Total on Overall Combination']['Column Name']],
                        self.use_decimal_precision)

                if self.__include_prefix:
                    df_new[self.sot_columns_dict['Percent on Overall Combination plus Prefix']['Column Name']] = \
                        round(
                            100 * df_new[
                                self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name']] /
                            df_new[self.sot_columns_dict['Total on Overall Combination']['Column Name']],
                            self.use_decimal_precision)
                    df_new[self.sot_columns_dict['Percent of Shared Policy Numbers on Prefix']['Column Name']] = \
                        round(100 * df_new[
                            self.sot_columns_dict['Count of Shared Policy Numbers on Prefix']['Column Name']] / df_new[
                                  self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name']],
                              self.use_decimal_precision)

                print(f'Size of DataFrame after Calculations & Removals:{df_new.shape}')

                df_new.drop(columns=[self.sot_columns_dict['Count of Self Policies']['Column Name'],
                                     self.sot_columns_dict['Count of Seniors']['Column Name'],
                                     self.sot_columns_dict['Count of Minors']['Column Name'],
                                     self.sot_columns_dict['Count of Unrelated Start Dates']['Column Name'],
                                     self.sot_columns_dict['Count of Shared Policy Numbers']['Column Name'],
                                     self.sot_columns_dict['Count of Individual Records']['Column Name']],
                            inplace=True)

                if self.__include_prefix:
                    df_new[self.sot_columns_dict['Percent Ceiling on Overall Combination plus Prefix']['Column Name']] = \
                        np.ceil(round(df_new[self.sot_columns_dict['Percent on Overall Combination plus Prefix'][
                            'Column Name']] / 10, self.use_decimal_precision))
                    df_new[self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers on Prefix']['Column Name']] = \
                        np.ceil(round(df_new[self.sot_columns_dict['Percent of Shared Policy Numbers on Prefix'][
                            'Column Name']] / 10, self.use_decimal_precision))

                df_new[self.sot_columns_dict['Percent Ceiling on Overall Combination']['Column Name']] = np.ceil(
                    df_new[self.sot_columns_dict['Percent on Overall Combination']['Column Name']] / 10)
                df_new[self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers']['Column Name']] = \
                    np.ceil(round(df_new[self.sot_columns_dict['Percent of Shared Policy Numbers']['Column Name']] / 10,
                                  self.use_decimal_precision))

                df_new[self.sot_columns_dict['Information for Next Recommended Carrier Code'][
                    'Column Name']] = df_new.apply(next_info, axis=1)
                if self.__include_prefix:
                    df_new[
                        self.sot_columns_dict['Information for Next Recommended Prefix']['Column Name']] = df_new.apply(
                        next_info, prefix_info=True, axis=1)

                print(f'Size of DataFrame after group_data_inner:{df_new.shape}')

                return df_new

            def remove_excess(df_removal: pd.DataFrame):
                # Create list of columns to rank by IN ORDER
                if self.__include_prefix:
                    rank_columns = [
                        self.sot_columns_dict['Percent Ceiling on Overall Combination plus Prefix']['Column Name'],
                        self.sot_columns_dict['Percent Ceiling on Overall Combination']['Column Name'],
                        self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers on Prefix']['Column Name'],
                        self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers']['Column Name'],
                        self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name'],
                        self.sot_columns_dict['Total on Overall Combination']['Column Name'],
                        self.sot_columns_dict['Column Selection Priority']['Column Name'],
                        self.sot_columns_dict['Column Selection Length']['Column Name'],
                        self.sot_columns_dict['Percent on Overall Combination plus Prefix']['Column Name'],
                        self.sot_columns_dict['Percent on Overall Combination']['Column Name'],
                        self.sot_columns_dict['Percent of Shared Policy Numbers on Prefix']['Column Name'],
                        self.sot_columns_dict['Percent of Shared Policy Numbers']['Column Name']]
                else:
                    rank_columns = [self.sot_columns_dict['Percent Ceiling on Overall Combination']['Column Name'],
                                    self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers']['Column Name'],
                                    self.sot_columns_dict['Total on Overall Combination']['Column Name'],
                                    self.sot_columns_dict['Column Selection Priority']['Column Name'],
                                    self.sot_columns_dict['Column Selection Length']['Column Name'],
                                    self.sot_columns_dict['Percent on Overall Combination']['Column Name'],
                                    self.sot_columns_dict['Percent of Shared Policy Numbers']['Column Name']]

                print(f'Size of DataFrame before Ranking Removals:{df_removal.shape}')
                df_new = multi_col_dense_rank_v7(df=df_removal, rank_columns=rank_columns, rank_name='RANK',
                                                 additional_group_by_col=self.all_discover_columns,
                                                 remove_all_but_best=True)
                print(f'Size of DataFrame after Ranking Removals:{df_new.shape}')

                return df_new

            def jigsaw_ranks_v3(inner_df: pd.DataFrame):
                ranked_df = inner_df.copy()
                jigsaw_df = pd.DataFrame()
                secondary_needed = (self.__include_prefix and self.__prefix_separate_from_carrier)

                if secondary_needed:  # Add in and self.__prefix_separate_from_carrier
                    rank_list = ['SECONDARY', 'PRIMARY']
                else:
                    rank_list = ['PRIMARY']

                for to_rank in rank_list:
                    if to_rank == 'SECONDARY':
                        rank_name = self.sot_columns_dict['Prefix Rank']['Column Name']
                        col_to_rank = [self.sot_columns_dict['Total on Overall Combination plus Prefix']['Column Name'],
                                       self.sot_columns_dict['Percent on Overall Combination plus Prefix'][
                                           'Column Name'],
                                       self.sot_columns_dict['Percent of Shared Policy Numbers on Prefix'][
                                           'Column Name']]
                        keep_right_col = [self.sot_columns_dict['Information for Next Recommended Prefix'][
                                              'Column Name'],
                                          self.sot_columns_dict['Recommended Prefix']['Column Name']]
                        extra_group_by = self.primary_discover_columns[:]
                    elif to_rank == 'PRIMARY':
                        if secondary_needed:
                            previous_rank_name = rank_name[:]

                        rank_name = self.sot_columns_dict['Overall Rank']['Column Name']
                        col_to_rank = [self.sot_columns_dict['Total on Overall Combination']['Column Name'],
                                       self.sot_columns_dict['Percent on Overall Combination']['Column Name'],
                                       self.sot_columns_dict['Percent of Shared Policy Numbers']['Column Name']]
                        keep_right_col = self.primary_discover_columns[:] + [
                            self.sot_columns_dict['Information for Next Recommended Carrier Code']['Column Name']]

                        if secondary_needed:
                            keep_right_col.extend([self.sot_columns_dict['Recommended Prefix']['Column Name'],
                                                   self.sot_columns_dict['Prefix Rank']['Column Name']])

                        extra_group_by = []
                    else:
                        raise TypeError(f"{to_rank} not expected")

                    ranked_df = multi_col_dense_rank_v7(df=ranked_df, rank_columns=col_to_rank, rank_name=rank_name,
                                                        additional_group_by_col=extra_group_by,
                                                        remove_all_but_best=False)
                    ranked_df[f'NEXT_{rank_name}'] = ranked_df[rank_name] + 1
                    left_join_col = self.initial_group_by_columns + extra_group_by + [f'NEXT_{rank_name}']
                    right_join_col = self.initial_group_by_columns + extra_group_by + [rank_name]
                    keep_right_col += right_join_col
                    right_df = ranked_df[keep_right_col].copy()
                    right_df.drop_duplicates(inplace=True)

                    if to_rank == 'SECONDARY':
                        jigsaw_df = pd.merge(ranked_df, right_df, left_on=left_join_col, right_on=right_join_col,
                                             how='left', suffixes=('', '_NEXT'))
                        jigsaw_df.drop(columns=[
                            self.sot_columns_dict['Information for Next Recommended Prefix']['Column Name'],
                            f"NEXT_{self.sot_columns_dict['Prefix Rank']['Column Name']}",
                            f"{self.sot_columns_dict['Prefix Rank']['Column Name']}_NEXT"], inplace=True)
                        jigsaw_df.rename(columns={
                            f"{self.sot_columns_dict['Recommended Prefix']['Column Name']}_NEXT":
                                self.sot_columns_dict['Next Recommended Prefix for Carrier']['Column Name'],
                            f"{self.sot_columns_dict['Information for Next Recommended Prefix']['Column Name']}_NEXT":
                                self.sot_columns_dict['Information for Next Recommended Prefix']['Column Name']},
                            inplace=True)
                        jigsaw_df[rank_name] = jigsaw_df[rank_name].astype('int')
                        ranked_df = jigsaw_df.loc[jigsaw_df[rank_name] <= 10].copy()
                        del jigsaw_df

                    elif to_rank == 'PRIMARY':
                        rename_dict = {
                            f"{self.sot_columns_dict['Recommended Carrier Code']['Column Name']}_NEXT":
                                self.sot_columns_dict['Next Recommended Carrier Code']['Column Name'],
                            f"{self.sot_columns_dict['Information for Next Recommended Carrier Code']['Column Name']}_NEXT":
                                self.sot_columns_dict['Information for Next Recommended Carrier Code'][
                                    'Column Name'],
                            f"{self.sot_columns_dict['Recommended Prefix']['Column Name']}_NEXT":
                                self.sot_columns_dict['Recommended Prefix for Next Carrier']['Column Name'],
                            f"{self.sot_columns_dict['Recommended Carrier Office Code']['Column Name']}_NEXT":
                                self.sot_columns_dict['Next Recommended Carrier Office Code']['Column Name'],
                        }
                        current_drop_columns = [
                            self.sot_columns_dict['Information for Next Recommended Carrier Code']['Column Name'],
                            f"NEXT_{self.sot_columns_dict['Overall Rank']['Column Name']}",
                            f"{self.sot_columns_dict['Overall Rank']['Column Name']}_NEXT"]

                        if secondary_needed:
                            right_df = right_df.loc[right_df[previous_rank_name] == 1]
                            current_drop_columns.extend([f"{self.sot_columns_dict['Prefix Rank']['Column Name']}_NEXT"])

                        jigsaw_df = pd.merge(ranked_df, right_df, left_on=left_join_col, right_on=right_join_col,
                                             how='left', suffixes=('', '_NEXT'))
                        jigsaw_df.drop(columns=current_drop_columns, inplace=True)
                        jigsaw_df.rename(columns=rename_dict, inplace=True)
                        jigsaw_df[rank_name] = jigsaw_df[rank_name].astype('int')

                return jigsaw_df

            start_time = datetime.datetime.now()

            # Start the new dataframe
            print('Start Grouping....')
            grouped_df = pd.DataFrame()
            for a in tqdm(self.group_by_combos_list, desc=f'Grouping Process', leave=False):
                print(f'\nGrouping {a}...')
                if len(a) == len(self.initial_group_by_columns):
                    group_data_inner_start_time = datetime.datetime.now()
                    grouped_df = group_data_inner(a)
                    group_data_inner_time = datetime.datetime.now() - group_data_inner_start_time
                else:
                    # print(f'Grouping: {a}...')
                    group_data_inner_start_time = datetime.datetime.now()
                    grouped_df = pd.concat([grouped_df, group_data_inner(a)], ignore_index=True, axis=0)
                    group_data_inner_time += datetime.datetime.now() - group_data_inner_start_time
                    # print('...Grouped!')
                    grouped_df = remove_excess(grouped_df)
                    # print('...Excess Removed!')
                print(f'\nCurrent Size of Final DataFrame: {grouped_df.shape}\n')
            print('All columns grouped!')

            # Rename irrelevant columns based on Column Selection
            print('\nRemoving irrelevant!')
            irrelevant_value = f'{self.empty_str}'
            grouped_df.loc[
                ~grouped_df[self.sot_columns_dict['Column Selection Letter']['Column Name']].str.contains('C', na=False
                                                                                                          ),
                self.database_dict['CARRIER CODE']['EMP'][
                    self.__known]] = irrelevant_value
            grouped_df.loc[
                ~grouped_df[self.sot_columns_dict['Column Selection Letter']['Column Name']].str.contains('E', na=False
                                                                                                          ),
                self.database_dict['EMPLOYER NAME']['EMP'][
                    self.__known]] = irrelevant_value
            grouped_df.loc[
                ~grouped_df[self.sot_columns_dict['Column Selection Letter']['Column Name']].str.contains('G', na=False
                                                                                                          ),
                self.database_dict['GROUP NUMBER']['EMP'][
                    self.__known]] = irrelevant_value
            grouped_df.loc[
                ~grouped_df[self.sot_columns_dict['Column Selection Letter']['Column Name']].str.contains('S', na=False
                                                                                                          ),
                self.database_dict['INSURED STATE CODE'][
                    'EMP']] = irrelevant_value
            print('...Irrelevant Removed!')
            print(f'{grouped_df.shape}')
            # Drop unneeded columns and duplicate rows
            print('\nDrop columns...')
            drop_columns = [self.sot_columns_dict['Column Selection Letter']['Column Name'],
                            self.sot_columns_dict['Column Selection Length']['Column Name'],
                            self.sot_columns_dict['Column Selection Priority']['Column Name'],
                            self.sot_columns_dict['Column Selection Concatenation']['Column Name'],
                            self.sot_columns_dict['Percent Ceiling on Overall Combination']['Column Name'],
                            self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers']['Column Name']]
            if self.__include_prefix:
                drop_columns.extend([
                    self.sot_columns_dict['Percent Ceiling of Shared Policy Numbers on Prefix']['Column Name'],
                    self.sot_columns_dict['Percent Ceiling on Overall Combination plus Prefix']['Column Name']])

            grouped_df.drop(columns=drop_columns, inplace=True)
            del drop_columns

            print(f'{grouped_df.shape}')
            print(f'\nSize of DataFrame: {grouped_df.shape}\n...drop rows...')
            grouped_df.drop_duplicates(inplace=True, ignore_index=True)
            print(f'Dropped\nSize of DataFrame: {grouped_df.shape}\n')

            # Create Recs
            print(f'\n\nRanking then getting recommendations...')
            rec_df = jigsaw_ranks_v3(grouped_df)
            print(f'{rec_df.shape}\nReplace None with Value...')
            rec_df[self.sot_columns_dict['Next Recommended Carrier Code']['Column Name']] = rec_df[
                self.sot_columns_dict['Next Recommended Carrier Code']['Column Name']].replace(np.nan, self.empty_str)
            rec_df[self.sot_columns_dict['Information for Next Recommended Carrier Code']['Column Name']] = (
                rec_df[self.sot_columns_dict['Information for Next Recommended Carrier Code']['Column Name']].replace(
                    np.nan, self.no_next_suggestion))
            if self.__include_prefix:
                rec_df[self.sot_columns_dict['Next Recommended Prefix for Carrier']['Column Name']] = rec_df[
                    self.sot_columns_dict['Next Recommended Prefix for Carrier']['Column Name']].replace(np.nan,
                                                                                                         self.empty_str)
                rec_df[self.sot_columns_dict['Information for Next Recommended Prefix']['Column Name']] = (
                    rec_df[self.sot_columns_dict['Information for Next Recommended Prefix']['Column Name']].replace(
                        np.nan, self.no_next_suggestion))
                rec_df[self.sot_columns_dict['Recommended Prefix for Next Carrier']['Column Name']] = rec_df[
                    self.sot_columns_dict['Recommended Prefix for Next Carrier']['Column Name']].replace(np.nan,
                                                                                                         self.empty_str)

            print(f'\nSize of DataFrame: {rec_df.shape}\n...drop rows...')
            rec_df.drop_duplicates(inplace=True, ignore_index=True)
            print(f'\nSize of DataFrame: {rec_df.shape}\nDropped!\nReady to Go!')

            print(f'Group Data with Rank Time: {datetime.datetime.now() - start_time}')
            print(f'Group Data Inner Time: {group_data_inner_time}')

            return rec_df

        def add_in_gap(df_grouped: pd.DataFrame):
            df_gap = read_sql_to_df(sql=self.sql_for_gap_data())
            df_gap = self.__strip_objects_clean(df_gap)
            print(f'Gap Dataframe:\n{df_gap.shape}\n\n{df_gap}\n\n'
                  f'\nMerge Gap Data with {self.initial_group_by_columns}...\n'
                  f'Left Data Types: {df_grouped.dtypes}\nRight Data Types:{df_gap.dtypes}\n')
            df = pd.merge(left=df_grouped, right=df_gap, on=self.initial_group_by_columns, how='left')

            # Make sure that the newest column is an int column and all blanks are replaced with zero
            df[df.columns[-1]] = df[df.columns[-1]].replace(np.nan, 0)
            df[df.columns[-1]] = df[df.columns[-1]].astype('int')

            return df

        def format_sot_table(df: pd.DataFrame):
            def change_format(row, col_name: str):
                initial_value = row[col_name]
                if initial_value == 100:
                    return_value = f"UNEQUIVOCAL: {initial_value:0.{self.__display_decimal_precision}f}%"
                elif initial_value >= 75:
                    return_value = f"TRUSTWORTHY: {initial_value:0.{self.__display_decimal_precision}f}%"
                elif initial_value > 50:
                    return_value = f"PLAUSIBLE: {initial_value:0.{self.__display_decimal_precision}f}%"
                elif initial_value == 50:
                    return_value = f"FIFTY-FIFTY: {initial_value:0.{self.__display_decimal_precision}f}%"
                    # neck and neck
                elif initial_value > 25:
                    return_value = f"FLIMSY: {initial_value:0.{self.__display_decimal_precision}f}%"
                elif initial_value >= 1:
                    return_value = f"DUBIOUS: {initial_value:0.{self.__display_decimal_precision}f}%"
                else:
                    return_value = f"ABYSMAL: {initial_value:0.{self.__display_decimal_precision}f}%"  # ABSURD
                return return_value

            def change_decimal(row, col_name: str):
                initial_value = row[col_name]
                return_value = round(initial_value, self.__display_decimal_precision)
                return return_value

            # Format all percentages to a string with the percentage
            column_list = list(df.columns)
            for col in column_list:
                if df.dtypes[col] == 'float64':
                    for key, value in self.sot_columns_dict.items():
                        if value['Column Name'] == col:
                            if 'CHAR' in value['SQL Datatype']:
                                df[col] = df.apply(change_format, col_name=col, axis=1)
                            elif 'DECIMAL' in value['SQL Datatype']:
                                df[col] = df.apply(change_decimal, col_name=col, axis=1)
                            break
                if df.dtypes[col] == 'object':
                    try:
                        df[col] = df[col].str.strip()
                    finally:
                        continue
            print('Formatting Percentages Complete!')

            # Restructure SOT Columns in Order: Create list of order + name then reduce to just name
            set_string = self.__create_set_string()
            set_list = list()
            for key, value in self.sot_columns_dict.items():
                if value[set_string]['Keep']:
                    set_list.append((value[set_string]['Order'], value['Column Name']))

            set_list.sort(key=lambda x: x[0])
            set_columns = [item[1] for item in set_list]
            print(f'Set Columns: {set_columns}')

            # Get Combo Number
            combo_df = self.__get_combo_numbers(df=df, send_to_table=send_to_table)
            on_columns = ([self.sot_columns_dict['Recommended Carrier Code']['Column Name']] +
                          self.initial_group_by_columns)
            df = df.merge(right=combo_df, on=on_columns, how='left')
            print(combo_df.columns)
            print(df.columns)

            # Add Create Date to Dataframe
            df[self.sot_columns_dict['Table Create Date']['Column Name']] = datetime.date.today()

            # Filter with list
            df = df.filter(set_columns, axis=1)

            return df

        ###############################
        # Code for the functions
        if self.data_in_csv:
            return_dataframe = pd.read_csv(self.starting_data_file_path, index_col=0)
        else:
            return_dataframe = self.__collect_all_data()
            if self.save_data:
                file_open = True
                while file_open:
                    try:
                        return_dataframe.to_csv(self.starting_data_file_path)
                        file_open = False
                    except PermissionError:
                        input(f"Close {self.starting_data_file_path} then press Enter to continue...")
                        file_open = True
        print(f'\n\nInitial Dataframe:\n{return_dataframe.shape}')
        return_dataframe = group_data_with_rank(return_dataframe)
        print(f'\nGrouping and Ranking Done!!!\n{return_dataframe.shape}\n\nGet Gap Data...')
        return_dataframe = add_in_gap(return_dataframe)
        print(f'Gaps Added!\n{return_dataframe.shape}')
        return_dataframe = format_sot_table(return_dataframe)
        if sot_save_file_and_path != '':
            file_open = True
            while file_open:
                try:
                    return_dataframe.to_csv(sot_save_file_and_path)
                    file_open = False
                except PermissionError:
                    input(f"Close {sot_save_file_and_path} then press Enter to continue...")
                    file_open = True
            print(f'Table Data saved in: {sot_save_file_and_path}')
        if send_to_table:
            if sot_database_name == '' or sot_table_name == '':
                if sot_database_name == '' and sot_table_name != '':
                    error_str = 'sot_database_name needs to be defined'
                elif sot_database_name != '' and sot_table_name == '':
                    error_str = 'sot_table_name needs to be defined'
                else:
                    error_str = 'Both sot_database_name and sot_table_name need to be defined.'
                raise ValueError(error_str)
            print(f'Creating Table and Sending Data to {dsn}: {sot_database_name}.{sot_table_name}')
            set_string = self.__create_set_string()
            self.__create_sql_table(df=return_dataframe, database_name=sot_database_name, table_name=sot_table_name,
                                    set_string=set_string, dsn=dsn)
            print('Data sent and table now available!')

        return return_dataframe


file_path = 'C:/Users/plight/OneDrive - Gainwell Technologies/Documents/Data Gap - Employer - Phoebe/'
file_name = 'SOT_K_P.csv'
if __name__ == '__main__':
    # Code Start Time
    start = datetime.datetime.now()
    dt_string = start.strftime("%m/%d/%Y %H:%M:%S.%f")
    print(f"Start: {dt_string}")

    # Run Code:
    start_sot = SOTKnowledgeCreation(discover='MED', known='RX', allow_known_to_equal_discover=False,
                                     include_base_dates=False, include_office_cd=False,
                                     include_prefix=False, blue_prefix_only=True, include_prefix_dates=False)
    #start_sot.small_sample = True
    #start_sot.small_sample_size = 5
    final_dataframe = start_sot.table_creation(sot_save_file_and_path=file_path + file_name, send_to_table=False)

    # pd.set_option('display.max_columns', None)
    # print(f'Dataframe Columns and types\n{final_dataframe.dtypes}\nFinal Dataframe:\n{final_dataframe}')

    # Code End Time
    end = datetime.datetime.now()
    dt_string = end.strftime("%m/%d/%Y %H:%M:%S.%f")
    print(f"Finish: {dt_string}")

    total_time = end - start
    print(f"Total Time: {total_time}")
